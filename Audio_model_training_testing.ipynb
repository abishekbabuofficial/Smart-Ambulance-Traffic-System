{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO3qCguvmbLb1P2QJWg0c11",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abishekbabuofficial/Smart-Ambulance-Traffic-System/blob/main/Audio_model_training_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UN9WtMXq6g_4",
        "outputId": "56aaa2c9-23a0-4b34-a373-e4d38f17c712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.11.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install librosa\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import resampy\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "metadata": {
        "id": "2dCum8B6C3KD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dont run this more than once\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adiVFUII7EW0",
        "outputId": "c395b2b9-6d88-40ff-f4e1-713fd4e80283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filen = \"/content/drive/MyDrive/SATS/Dataset/Audio_Dataset\"\n",
        "data, sample_rate = librosa.load(\"/content/drive/MyDrive/SATS/Dataset/Audio_Dataset/VehicleNoise0.wav\")\n",
        "plt.figure(figsize=(12, 5))\n",
        "librosa.display.waveshow(data, sr=sample_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "Vm0IJugpCSft",
        "outputId": "a19b8e9d-fa53-4303-e3ff-a75970eab9da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<librosa.display.AdaptiveWaveplot at 0x7aa066843e80>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing csv file\n",
        "metadata = pd.read_csv('/content/drive/MyDrive/SATS/Dataset/sounds.csv')\n",
        "metadata.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "iHT0xh8cDIco",
        "outputId": "acd92ece-1173-4527-b48d-b2deb2835874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           File      Label\n",
              "0   sound_1.wav  ambulance\n",
              "1   sound_2.wav  ambulance\n",
              "2   sound_3.wav  ambulance\n",
              "3   sound_4.wav  ambulance\n",
              "4   sound_5.wav  ambulance\n",
              "5   sound_6.wav  ambulance\n",
              "6   sound_7.wav  ambulance\n",
              "7   sound_8.wav  ambulance\n",
              "8   sound_9.wav  ambulance\n",
              "9  sound_10.wav  ambulance"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca9884b4-97cc-4a00-8d3b-8d6dc0432aa8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sound_1.wav</td>\n",
              "      <td>ambulance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sound_2.wav</td>\n",
              "      <td>ambulance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sound_3.wav</td>\n",
              "      <td>ambulance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sound_4.wav</td>\n",
              "      <td>ambulance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sound_5.wav</td>\n",
              "      <td>ambulance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sound_6.wav</td>\n",
              "      <td>ambulance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>sound_7.wav</td>\n",
              "      <td>ambulance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>sound_8.wav</td>\n",
              "      <td>ambulance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>sound_9.wav</td>\n",
              "      <td>ambulance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sound_10.wav</td>\n",
              "      <td>ambulance</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca9884b4-97cc-4a00-8d3b-8d6dc0432aa8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ca9884b4-97cc-4a00-8d3b-8d6dc0432aa8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ca9884b4-97cc-4a00-8d3b-8d6dc0432aa8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f6bb4b36-6af0-431b-89d3-4c25c70ac5ff\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f6bb4b36-6af0-431b-89d3-4c25c70ac5ff')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f6bb4b36-6af0-431b-89d3-4c25c70ac5ff button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "metadata",
              "summary": "{\n  \"name\": \"metadata\",\n  \"rows\": 602,\n  \"fields\": [\n    {\n      \"column\": \"File\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 602,\n        \"samples\": [\n          \"sound_111.wav\",\n          \"VehicleNoise19.wav\",\n          \"VehicleNoise566.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"ambulance\",\n          \"traffic\",\n          \"other\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No charts were generated by quickchart\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#observing the metadata\n",
        "metadata['Label'].value_counts()\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(metadata['Label'])\n",
        "plt.title(\"Count of records in each class\")\n",
        "plt.xticks(rotation=\"vertical\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "gfQnXRiED55F",
        "outputId": "e7e4dfb3-696d-4b50-9af7-4b6d2eeca8be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "0I_w9OLMEqhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install resampy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj_t3eOqF3M0",
        "outputId": "467dacc6-74fe-4655-9be5-deddbe14e69d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting resampy\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from resampy) (1.25.2)\n",
            "Requirement already satisfied: numba>=0.53 in /usr/local/lib/python3.10/dist-packages (from resampy) (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.53->resampy) (0.41.1)\n",
            "Installing collected packages: resampy\n",
            "Successfully installed resampy-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_n = \"/content/drive/MyDrive/SATS/Dataset/Audio_Dataset/sound_1.wav\"\n",
        "audio, sample_rate = librosa.load(file_n)\n",
        "mfccs = librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=40)\n",
        "print(mfccs.shape)\n",
        "print(mfccs)\n",
        "plt.figure(figsize=(10, 5))\n",
        "librosa.display.specshow(mfccs, x_axis='time')\n",
        "plt.colorbar()\n",
        "plt.title('MFCC')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('MFCC Coefficients')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "j1svkTCIEjuR",
        "outputId": "7ad67499-0c6a-4dd1-a242-c5894a841a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 222)\n",
            "[[-5.52276306e+02 -5.21882324e+02 -5.20683594e+02 ... -3.59206512e+02\n",
            "  -3.61202972e+02 -3.81763519e+02]\n",
            " [ 1.22615463e+02  1.17594795e+02  1.14812508e+02 ...  1.43645737e+02\n",
            "   1.40115540e+02  1.41349457e+02]\n",
            " [ 1.32874084e+00 -2.75524426e+00 -6.35500383e+00 ... -6.03234863e+00\n",
            "  -7.18128490e+00 -9.93573380e+00]\n",
            " ...\n",
            " [ 2.34596729e-02  3.67674446e+00  2.64645314e+00 ... -4.36732149e+00\n",
            "  -4.22320652e+00 -2.76453280e+00]\n",
            " [-1.04737291e+01 -9.94772243e+00 -8.44275951e+00 ... -7.07656574e+00\n",
            "  -3.43004036e+00 -2.40012348e-01]\n",
            " [-1.56644344e-01 -2.01474905e+00 -1.37364841e+00 ... -3.85784721e+00\n",
            "   1.18426788e+00  8.34406853e-01]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import resampy"
      ],
      "metadata": {
        "id": "7-eDKUeVK5jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def features_extractor(file_name):\n",
        "    #load the file (audio)\n",
        "    audio, sample_rate = librosa.load(file_name)\n",
        "    #we extract mfcc\n",
        "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    #in order to find out scaled feature we do mean of transpose of value\n",
        "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "    return mfccs_scaled_features"
      ],
      "metadata": {
        "id": "lZMjik8_Ipbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Now we iterate through every audio file and extract features\n",
        "### using Mel-Frequency Cepstral Coefficients\n",
        "extracted_features=[]\n",
        "for index_num,row in tqdm(metadata.iterrows()):\n",
        "    file_name = os.path.join(os.path.abspath(filen)+'/',str(row[\"File\"]))\n",
        "    final_class_labels=row[\"Label\"]\n",
        "    data=features_extractor(file_name)\n",
        "    extracted_features.append([data,final_class_labels])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNYyvLdXI1ty",
        "outputId": "90062df1-be99-462e-cb9c-3d6dcdb7c9a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "602it [04:50,  2.07it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
        "extracted_features_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iDZBAUDFQSSc",
        "outputId": "10948598-f4be-443c-c899-c037bf8a62d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             feature      class\n",
              "0  [-528.137, 94.48654, -45.078938, -14.321531, -...  ambulance\n",
              "1  [-478.67493, 107.74389, -78.45012, -3.827537, ...  ambulance\n",
              "2  [-423.91934, 107.58114, -64.02175, -4.905348, ...  ambulance\n",
              "3  [-395.38745, 41.017452, -35.12465, -31.807873,...  ambulance\n",
              "4  [-341.77274, 57.169716, -48.171936, -28.324432...  ambulance"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74cda73a-2b96-4f13-be62-c52275215252\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-528.137, 94.48654, -45.078938, -14.321531, -...</td>\n",
              "      <td>ambulance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-478.67493, 107.74389, -78.45012, -3.827537, ...</td>\n",
              "      <td>ambulance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-423.91934, 107.58114, -64.02175, -4.905348, ...</td>\n",
              "      <td>ambulance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-395.38745, 41.017452, -35.12465, -31.807873,...</td>\n",
              "      <td>ambulance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-341.77274, 57.169716, -48.171936, -28.324432...</td>\n",
              "      <td>ambulance</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74cda73a-2b96-4f13-be62-c52275215252')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-74cda73a-2b96-4f13-be62-c52275215252 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-74cda73a-2b96-4f13-be62-c52275215252');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c5a53418-5d04-473b-8d87-19c183b7afc2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c5a53418-5d04-473b-8d87-19c183b7afc2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c5a53418-5d04-473b-8d87-19c183b7afc2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "extracted_features_df",
              "summary": "{\n  \"name\": \"extracted_features_df\",\n  \"rows\": 602,\n  \"fields\": [\n    {\n      \"column\": \"feature\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"ambulance\",\n          \"traffic\",\n          \"other\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data spliting"
      ],
      "metadata": {
        "id": "j640dErnQvde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "XYQ_-wZLREgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Split the dataset into independent and dependent dataset\n",
        "X=np.array(extracted_features_df['feature'].tolist())\n",
        "y=np.array(extracted_features_df['class'].tolist())\n",
        "### Label Encoding -> Label Encoder\n",
        "labelencoder=LabelEncoder()\n",
        "y=to_categorical(labelencoder.fit_transform(y))\n",
        "### Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "eyJVHZl1QmUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ],
      "metadata": {
        "id": "TQHRu1agRN2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "PfSbJHCrRRKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### No of classes\n",
        "num_labels=y.shape[1]\n",
        "model=Sequential()\n",
        "###first layer\n",
        "model.add(Dense(100,input_shape=(40,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "###second layer\n",
        "model.add(Dense(200))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "###third layer\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "###final layer\n",
        "model.add(Dense(num_labels))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "HhqzMJUARVUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "O-2nJWcQR7i3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "zwTZOAItR5eO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 500\n",
        "num_batch_size = 24\n",
        "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
        "checkpointer = ModelCheckpoint(filepath='./audio_classification.hdf5',\n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "train = model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUl3-op8SB7R",
        "outputId": "4c9f74dc-d722-40d2-a943-78592c7f7742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 4.6566e-08 - accuracy: 1.0000 \n",
            "Epoch 1: val_loss improved from inf to 0.53397, saving model to ./audio_classification.hdf5\n",
            "21/21 [==============================] - 2s 14ms/step - loss: 5.1550e-08 - accuracy: 1.0000 - val_loss: 0.5340 - val_accuracy: 0.9835\n",
            "Epoch 2/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 5.2775e-09 - accuracy: 1.0000\n",
            "Epoch 2: val_loss improved from 0.53397 to 0.52827, saving model to ./audio_classification.hdf5\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 7.4274e-05 - accuracy: 1.0000 - val_loss: 0.5283 - val_accuracy: 0.9752\n",
            "Epoch 3/500\n",
            " 1/21 [>.............................] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16/21 [=====================>........] - ETA: 0s - loss: 0.0148 - accuracy: 0.9974    \n",
            "Epoch 3: val_loss improved from 0.52827 to 0.51819, saving model to ./audio_classification.hdf5\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0118 - accuracy: 0.9979 - val_loss: 0.5182 - val_accuracy: 0.9835\n",
            "Epoch 4/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 2.1064e-05 - accuracy: 1.0000\n",
            "Epoch 4: val_loss improved from 0.51819 to 0.50925, saving model to ./audio_classification.hdf5\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.4766e-05 - accuracy: 1.0000 - val_loss: 0.5093 - val_accuracy: 0.9917\n",
            "Epoch 5/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 5.5473e-07 - accuracy: 1.0000\n",
            "Epoch 5: val_loss improved from 0.50925 to 0.50331, saving model to ./audio_classification.hdf5\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 6.2378e-07 - accuracy: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.9917\n",
            "Epoch 6/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 1.1722e-07 - accuracy: 1.0000\n",
            "Epoch 6: val_loss improved from 0.50331 to 0.42734, saving model to ./audio_classification.hdf5\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 8.7733e-08 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.9917\n",
            "Epoch 7/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0297 - accuracy: 0.9974    \n",
            "Epoch 7: val_loss improved from 0.42734 to 0.40835, saving model to ./audio_classification.hdf5\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0237 - accuracy: 0.9979 - val_loss: 0.4084 - val_accuracy: 0.9917\n",
            "Epoch 8/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 8: val_loss improved from 0.40835 to 0.37166, saving model to ./audio_classification.hdf5\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.9917\n",
            "Epoch 9/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0143 - accuracy: 0.9974    \n",
            "Epoch 9: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0114 - accuracy: 0.9979 - val_loss: 0.4621 - val_accuracy: 0.9917\n",
            "Epoch 10/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0619 - accuracy: 0.9972    \n",
            "Epoch 10: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0546 - accuracy: 0.9958 - val_loss: 0.4578 - val_accuracy: 0.9917\n",
            "Epoch 11/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000    \n",
            "Epoch 11: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 9.9209e-04 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.9917\n",
            "Epoch 12/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0073 - accuracy: 0.9974    \n",
            "Epoch 12: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.4201 - val_accuracy: 0.9917\n",
            "Epoch 13/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0129 - accuracy: 0.9974    \n",
            "Epoch 13: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.4406 - val_accuracy: 0.9917\n",
            "Epoch 14/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000    \n",
            "Epoch 14: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4810 - val_accuracy: 0.9917\n",
            "Epoch 15/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 4.6164e-08 - accuracy: 1.0000\n",
            "Epoch 15: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.9158e-08 - accuracy: 1.0000 - val_loss: 0.4729 - val_accuracy: 0.9917\n",
            "Epoch 16/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 16: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 7.4351e-09 - accuracy: 1.0000 - val_loss: 0.4730 - val_accuracy: 0.9917\n",
            "Epoch 17/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 2.6588e-08 - accuracy: 1.0000\n",
            "Epoch 17: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.2553e-08 - accuracy: 1.0000 - val_loss: 0.4752 - val_accuracy: 0.9917\n",
            "Epoch 18/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 18: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.9917\n",
            "Epoch 19/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 0.0361 - accuracy: 0.9975    \n",
            "Epoch 19: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0306 - accuracy: 0.9979 - val_loss: 0.4402 - val_accuracy: 0.9917\n",
            "Epoch 20/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 1.6731e-06 - accuracy: 1.0000\n",
            "Epoch 20: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.8137e-06 - accuracy: 1.0000 - val_loss: 0.5172 - val_accuracy: 0.9917\n",
            "Epoch 21/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0235 - accuracy: 0.9974    \n",
            "Epoch 21: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 0.9979 - val_loss: 0.6065 - val_accuracy: 0.9917\n",
            "Epoch 22/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 6.0690e-04 - accuracy: 1.0000\n",
            "Epoch 22: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 5.1479e-04 - accuracy: 1.0000 - val_loss: 0.6432 - val_accuracy: 0.9835\n",
            "Epoch 23/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 2.7944e-04 - accuracy: 1.0000\n",
            "Epoch 23: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.3703e-04 - accuracy: 1.0000 - val_loss: 0.6173 - val_accuracy: 0.9835\n",
            "Epoch 24/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 2.0160e-08 - accuracy: 1.0000\n",
            "Epoch 24: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.7101e-08 - accuracy: 1.0000 - val_loss: 0.6156 - val_accuracy: 0.9835\n",
            "Epoch 25/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
            "Epoch 25: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 9.5127e-04 - accuracy: 1.0000 - val_loss: 0.7395 - val_accuracy: 0.9669\n",
            "Epoch 26/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 7.8888e-09 - accuracy: 1.0000\n",
            "Epoch 26: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 6.6916e-09 - accuracy: 1.0000 - val_loss: 0.7795 - val_accuracy: 0.9669\n",
            "Epoch 27/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 7.2876e-06 - accuracy: 1.0000\n",
            "Epoch 27: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 5.8180e-06 - accuracy: 1.0000 - val_loss: 0.7500 - val_accuracy: 0.9752\n",
            "Epoch 28/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 28: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0670 - accuracy: 0.9979 - val_loss: 0.7347 - val_accuracy: 0.9752\n",
            "Epoch 29/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0612 - accuracy: 0.9974    \n",
            "Epoch 29: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0489 - accuracy: 0.9979 - val_loss: 0.7102 - val_accuracy: 0.9835\n",
            "Epoch 30/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 5.2300e-08 - accuracy: 1.0000\n",
            "Epoch 30: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 4.4362e-08 - accuracy: 1.0000 - val_loss: 0.6909 - val_accuracy: 0.9835\n",
            "Epoch 31/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 6.3105e-07 - accuracy: 1.0000\n",
            "Epoch 31: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 0.9979 - val_loss: 0.6613 - val_accuracy: 0.9917\n",
            "Epoch 32/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 3.9447e-06 - accuracy: 1.0000\n",
            "Epoch 32: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.6386e-05 - accuracy: 1.0000 - val_loss: 0.6216 - val_accuracy: 0.9917\n",
            "Epoch 33/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 5.5222e-08 - accuracy: 1.0000\n",
            "Epoch 33: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 4.6841e-08 - accuracy: 1.0000 - val_loss: 0.6253 - val_accuracy: 0.9917\n",
            "Epoch 34/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000    \n",
            "Epoch 34: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6613 - val_accuracy: 0.9917\n",
            "Epoch 35/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 5.7098e-05 - accuracy: 1.0000\n",
            "Epoch 35: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 4.2770e-05 - accuracy: 1.0000 - val_loss: 0.7089 - val_accuracy: 0.9835\n",
            "Epoch 36/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 1.1687e-09 - accuracy: 1.0000\n",
            "Epoch 36: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 9.9135e-10 - accuracy: 1.0000 - val_loss: 0.7378 - val_accuracy: 0.9835\n",
            "Epoch 37/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0064 - accuracy: 0.9970\n",
            "Epoch 37: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 0.9979 - val_loss: 0.7415 - val_accuracy: 0.9835\n",
            "Epoch 38/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 38: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.7054 - val_accuracy: 0.9835\n",
            "Epoch 39/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 39: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.7002 - val_accuracy: 0.9835\n",
            "Epoch 40/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 40: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.6995 - val_accuracy: 0.9835\n",
            "Epoch 41/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 6.2088e-10 - accuracy: 1.0000\n",
            "Epoch 41: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0110 - accuracy: 0.9979 - val_loss: 0.7924 - val_accuracy: 0.9835\n",
            "Epoch 42/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 2.1731e-09 - accuracy: 1.0000\n",
            "Epoch 42: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.7349e-09 - accuracy: 1.0000 - val_loss: 1.0849 - val_accuracy: 0.9669\n",
            "Epoch 43/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 43: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1148 - val_accuracy: 0.9669\n",
            "Epoch 44/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 2.1048e-04 - accuracy: 1.0000\n",
            "Epoch 44: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.6803e-04 - accuracy: 1.0000 - val_loss: 0.9751 - val_accuracy: 0.9752\n",
            "Epoch 45/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 9.3132e-10 - accuracy: 1.0000\n",
            "Epoch 45: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.4366e-04 - accuracy: 1.0000 - val_loss: 0.9055 - val_accuracy: 0.9752\n",
            "Epoch 46/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 0.0151 - accuracy: 0.9951    \n",
            "Epoch 46: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.8326 - val_accuracy: 0.9752\n",
            "Epoch 47/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 3.0452e-07 - accuracy: 1.0000\n",
            "Epoch 47: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0209 - accuracy: 0.9979 - val_loss: 0.7692 - val_accuracy: 0.9835\n",
            "Epoch 48/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 48: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.4499e-06 - accuracy: 1.0000 - val_loss: 0.6455 - val_accuracy: 0.9917\n",
            "Epoch 49/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0031 - accuracy: 0.9972    \n",
            "Epoch 49: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 0.9979 - val_loss: 0.7714 - val_accuracy: 0.9835\n",
            "Epoch 50/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 9.7735e-06 - accuracy: 1.0000\n",
            "Epoch 50: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 9.0296e-06 - accuracy: 1.0000 - val_loss: 0.8538 - val_accuracy: 0.9752\n",
            "Epoch 51/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 2.9460e-07 - accuracy: 1.0000\n",
            "Epoch 51: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.3519e-07 - accuracy: 1.0000 - val_loss: 0.8565 - val_accuracy: 0.9752\n",
            "Epoch 52/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 3.7253e-09 - accuracy: 1.0000\n",
            "Epoch 52: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.9740e-09 - accuracy: 1.0000 - val_loss: 0.8483 - val_accuracy: 0.9752\n",
            "Epoch 53/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 2.5003e-06 - accuracy: 1.0000\n",
            "Epoch 53: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.9966e-06 - accuracy: 1.0000 - val_loss: 0.8366 - val_accuracy: 0.9752\n",
            "Epoch 54/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 2.9218e-10 - accuracy: 1.0000\n",
            "Epoch 54: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 4.9567e-10 - accuracy: 1.0000 - val_loss: 0.8297 - val_accuracy: 0.9835\n",
            "Epoch 55/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 55: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.8288 - val_accuracy: 0.9835\n",
            "Epoch 56/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 56: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.4784e-10 - accuracy: 1.0000 - val_loss: 0.8287 - val_accuracy: 0.9835\n",
            "Epoch 57/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 57: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0249 - accuracy: 0.9979 - val_loss: 0.7260 - val_accuracy: 0.9835\n",
            "Epoch 58/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 7.5967e-09 - accuracy: 1.0000\n",
            "Epoch 58: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 6.4437e-09 - accuracy: 1.0000 - val_loss: 0.5885 - val_accuracy: 0.9917\n",
            "Epoch 59/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 1.8626e-09 - accuracy: 1.0000\n",
            "Epoch 59: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.4870e-09 - accuracy: 1.0000 - val_loss: 0.5891 - val_accuracy: 0.9917\n",
            "Epoch 60/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 9.9341e-09 - accuracy: 1.0000\n",
            "Epoch 60: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 3.8662e-08 - accuracy: 1.0000 - val_loss: 0.5890 - val_accuracy: 0.9917\n",
            "Epoch 61/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 1.2418e-09 - accuracy: 1.0000\n",
            "Epoch 61: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2392e-09 - accuracy: 1.0000 - val_loss: 0.5891 - val_accuracy: 0.9917\n",
            "Epoch 62/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 5.7025e-06 - accuracy: 1.0000\n",
            "Epoch 62: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4.2407e-06 - accuracy: 1.0000 - val_loss: 0.6131 - val_accuracy: 0.9917\n",
            "Epoch 63/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 1.8316e-08 - accuracy: 1.0000\n",
            "Epoch 63: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4622e-08 - accuracy: 1.0000 - val_loss: 0.6276 - val_accuracy: 0.9917\n",
            "Epoch 64/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 5.5385e-05 - accuracy: 1.0000\n",
            "Epoch 64: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4.4224e-05 - accuracy: 1.0000 - val_loss: 0.5715 - val_accuracy: 0.9917\n",
            "Epoch 65/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 2.7940e-08 - accuracy: 1.0000\n",
            "Epoch 65: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.2305e-08 - accuracy: 1.0000 - val_loss: 0.5588 - val_accuracy: 0.9917\n",
            "Epoch 66/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 6.2087e-08 - accuracy: 1.0000\n",
            "Epoch 66: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 4.9567e-08 - accuracy: 1.0000 - val_loss: 0.5658 - val_accuracy: 0.9917\n",
            "Epoch 67/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 8.3047e-06 - accuracy: 1.0000\n",
            "Epoch 67: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 6.6312e-06 - accuracy: 1.0000 - val_loss: 0.5678 - val_accuracy: 0.9917\n",
            "Epoch 68/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 68: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.5682 - val_accuracy: 0.9917\n",
            "Epoch 69/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 5.8436e-10 - accuracy: 1.0000\n",
            "Epoch 69: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 4.9567e-10 - accuracy: 1.0000 - val_loss: 0.5682 - val_accuracy: 0.9917\n",
            "Epoch 70/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 6.7675e-08 - accuracy: 1.0000\n",
            "Epoch 70: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 5.4523e-08 - accuracy: 1.0000 - val_loss: 0.5681 - val_accuracy: 0.9917\n",
            "Epoch 71/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 71: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.5681 - val_accuracy: 0.9917\n",
            "Epoch 72/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 2.2392e-06 - accuracy: 1.0000\n",
            "Epoch 72: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.7876e-06 - accuracy: 1.0000 - val_loss: 0.5690 - val_accuracy: 0.9917\n",
            "Epoch 73/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 9.6420e-05 - accuracy: 1.0000\n",
            "Epoch 73: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 7.2187e-05 - accuracy: 1.0000 - val_loss: 0.5816 - val_accuracy: 0.9917\n",
            "Epoch 74/500\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9979\n",
            "Epoch 74: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 0.0048 - accuracy: 0.9979 - val_loss: 0.5863 - val_accuracy: 0.9917\n",
            "Epoch 75/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 75: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0119 - accuracy: 0.9979 - val_loss: 0.6659 - val_accuracy: 0.9835\n",
            "Epoch 76/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 76: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 4.9567e-10 - accuracy: 1.0000 - val_loss: 0.7498 - val_accuracy: 0.9835\n",
            "Epoch 77/500\n",
            "10/21 [=============>................] - ETA: 0s - loss: 0.0373 - accuracy: 0.9958    \n",
            "Epoch 77: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0186 - accuracy: 0.9979 - val_loss: 0.7144 - val_accuracy: 0.9917\n",
            "Epoch 78/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 6.7504e-07 - accuracy: 1.0000\n",
            "Epoch 78: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 4.0418e-07 - accuracy: 1.0000 - val_loss: 0.7147 - val_accuracy: 0.9917\n",
            "Epoch 79/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 1.9104e-09 - accuracy: 1.0000\n",
            "Epoch 79: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.2392e-09 - accuracy: 1.0000 - val_loss: 0.7148 - val_accuracy: 0.9917\n",
            "Epoch 80/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 7.5333e-08 - accuracy: 1.0000\n",
            "Epoch 80: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 4.5106e-08 - accuracy: 1.0000 - val_loss: 0.7142 - val_accuracy: 0.9917\n",
            "Epoch 81/500\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 3.2286e-09 - accuracy: 1.0000\n",
            "Epoch 81: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 3.2219e-09 - accuracy: 1.0000 - val_loss: 0.7142 - val_accuracy: 0.9917\n",
            "Epoch 82/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 82: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 2.1197e-04 - accuracy: 1.0000 - val_loss: 0.7156 - val_accuracy: 0.9917\n",
            "Epoch 83/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 3.3114e-09 - accuracy: 1.0000\n",
            "Epoch 83: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.8340e-08 - accuracy: 1.0000 - val_loss: 0.7167 - val_accuracy: 0.9917\n",
            "Epoch 84/500\n",
            "11/21 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 84: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7145 - val_accuracy: 0.9917\n",
            "Epoch 85/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 1.0348e-08 - accuracy: 1.0000\n",
            "Epoch 85: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 9.9134e-09 - accuracy: 1.0000 - val_loss: 0.7057 - val_accuracy: 0.9917\n",
            "Epoch 86/500\n",
            "11/21 [==============>...............] - ETA: 0s - loss: 2.3749e-05 - accuracy: 1.0000\n",
            "Epoch 86: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.3035e-05 - accuracy: 1.0000 - val_loss: 0.7047 - val_accuracy: 0.9917\n",
            "Epoch 87/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 87: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.7046 - val_accuracy: 0.9917\n",
            "Epoch 88/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 2.2019e-06 - accuracy: 1.0000\n",
            "Epoch 88: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 1.4283e-06 - accuracy: 1.0000 - val_loss: 0.7047 - val_accuracy: 0.9917\n",
            "Epoch 89/500\n",
            "11/21 [==============>...............] - ETA: 0s - loss: 4.5155e-10 - accuracy: 1.0000\n",
            "Epoch 89: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.0140 - accuracy: 0.9979 - val_loss: 0.6887 - val_accuracy: 0.9917\n",
            "Epoch 90/500\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 90: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.6802 - val_accuracy: 0.9917\n",
            "Epoch 91/500\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 91: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.6793 - val_accuracy: 0.9917\n",
            "Epoch 92/500\n",
            "21/21 [==============================] - ETA: 0s - loss: 6.9889e-08 - accuracy: 1.0000\n",
            "Epoch 92: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 6.9889e-08 - accuracy: 1.0000 - val_loss: 0.6812 - val_accuracy: 0.9917\n",
            "Epoch 93/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 7.5491e-07 - accuracy: 1.0000\n",
            "Epoch 93: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 4.5696e-07 - accuracy: 1.0000 - val_loss: 0.6816 - val_accuracy: 0.9917\n",
            "Epoch 94/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 4.2957e-04 - accuracy: 1.0000\n",
            "Epoch 94: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.9979 - val_loss: 0.6277 - val_accuracy: 0.9917\n",
            "Epoch 95/500\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 95: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.6461 - val_accuracy: 0.9835\n",
            "Epoch 96/500\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 96: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.6540 - val_accuracy: 0.9835\n",
            "Epoch 97/500\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 4.9671e-10 - accuracy: 1.0000\n",
            "Epoch 97: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 4.9567e-10 - accuracy: 1.0000 - val_loss: 0.6549 - val_accuracy: 0.9835\n",
            "Epoch 98/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 98: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 4.8080e-08 - accuracy: 1.0000 - val_loss: 0.6552 - val_accuracy: 0.9835\n",
            "Epoch 99/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 99: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.6558 - val_accuracy: 0.9835\n",
            "Epoch 100/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 2.0179e-08 - accuracy: 1.0000\n",
            "Epoch 100: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.6109e-08 - accuracy: 1.0000 - val_loss: 0.6561 - val_accuracy: 0.9835\n",
            "Epoch 101/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 101: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.6562 - val_accuracy: 0.9835\n",
            "Epoch 102/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 102: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.6562 - val_accuracy: 0.9835\n",
            "Epoch 103/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 103: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 5.6258e-08 - accuracy: 1.0000 - val_loss: 0.6538 - val_accuracy: 0.9835\n",
            "Epoch 104/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 104: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.6483 - val_accuracy: 0.9835\n",
            "Epoch 105/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 3.1044e-10 - accuracy: 1.0000\n",
            "Epoch 105: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.4784e-10 - accuracy: 1.0000 - val_loss: 0.6477 - val_accuracy: 0.9835\n",
            "Epoch 106/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 106: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 0.9835\n",
            "Epoch 107/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 107: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 0.9835\n",
            "Epoch 108/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 108: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.6476 - val_accuracy: 0.9835\n",
            "Epoch 109/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
            "Epoch 109: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 8.2523e-04 - accuracy: 1.0000 - val_loss: 0.7248 - val_accuracy: 0.9835\n",
            "Epoch 110/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 110: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.7592 - val_accuracy: 0.9835\n",
            "Epoch 111/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 4.7663e-05 - accuracy: 1.0000\n",
            "Epoch 111: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.8051e-05 - accuracy: 1.0000 - val_loss: 0.7978 - val_accuracy: 0.9835\n",
            "Epoch 112/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 112: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.8036 - val_accuracy: 0.9835\n",
            "Epoch 113/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 8.5991e-08 - accuracy: 1.0000\n",
            "Epoch 113: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 6.8650e-08 - accuracy: 1.0000 - val_loss: 0.8052 - val_accuracy: 0.9835\n",
            "Epoch 114/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 114: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.8057 - val_accuracy: 0.9835\n",
            "Epoch 115/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 2.3375e-07 - accuracy: 1.0000\n",
            "Epoch 115: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.8661e-07 - accuracy: 1.0000 - val_loss: 0.7996 - val_accuracy: 0.9835\n",
            "Epoch 116/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 6.2205e-07 - accuracy: 1.0000\n",
            "Epoch 116: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4.9660e-07 - accuracy: 1.0000 - val_loss: 0.8013 - val_accuracy: 0.9835\n",
            "Epoch 117/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 1.2418e-08 - accuracy: 1.0000\n",
            "Epoch 117: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3383e-08 - accuracy: 1.0000 - val_loss: 0.8029 - val_accuracy: 0.9835\n",
            "Epoch 118/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 118: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 7.2367e-08 - accuracy: 1.0000 - val_loss: 0.7998 - val_accuracy: 0.9835\n",
            "Epoch 119/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 119: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.7912 - val_accuracy: 0.9835\n",
            "Epoch 120/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 120: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.7903 - val_accuracy: 0.9835\n",
            "Epoch 121/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000    \n",
            "Epoch 121: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9466 - val_accuracy: 0.9752\n",
            "Epoch 122/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 122: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9825 - val_accuracy: 0.9752\n",
            "Epoch 123/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 1.7695e-08 - accuracy: 1.0000\n",
            "Epoch 123: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.4127e-08 - accuracy: 1.0000 - val_loss: 0.9870 - val_accuracy: 0.9752\n",
            "Epoch 124/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 124: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9879 - val_accuracy: 0.9752\n",
            "Epoch 125/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 125: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9880 - val_accuracy: 0.9752\n",
            "Epoch 126/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 6.2088e-10 - accuracy: 1.0000\n",
            "Epoch 126: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4.9567e-10 - accuracy: 1.0000 - val_loss: 0.9881 - val_accuracy: 0.9752\n",
            "Epoch 127/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 127: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9881 - val_accuracy: 0.9752\n",
            "Epoch 128/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 4.9511e-06 - accuracy: 1.0000\n",
            "Epoch 128: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 4.1997e-06 - accuracy: 1.0000 - val_loss: 0.9914 - val_accuracy: 0.9752\n",
            "Epoch 129/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 129: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9778 - val_accuracy: 0.9752\n",
            "Epoch 130/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 130: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9763 - val_accuracy: 0.9752\n",
            "Epoch 131/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 131: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9761 - val_accuracy: 0.9752\n",
            "Epoch 132/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 3.0423e-08 - accuracy: 1.0000\n",
            "Epoch 132: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.4288e-08 - accuracy: 1.0000 - val_loss: 0.9754 - val_accuracy: 0.9752\n",
            "Epoch 133/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 133: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9752 - val_accuracy: 0.9752\n",
            "Epoch 134/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 4.6566e-09 - accuracy: 1.0000\n",
            "Epoch 134: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.7175e-09 - accuracy: 1.0000 - val_loss: 0.9753 - val_accuracy: 0.9752\n",
            "Epoch 135/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 135: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 2.9740e-09 - accuracy: 1.0000 - val_loss: 0.9754 - val_accuracy: 0.9752\n",
            "Epoch 136/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 6.2088e-10 - accuracy: 1.0000\n",
            "Epoch 136: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4.9567e-10 - accuracy: 1.0000 - val_loss: 0.9756 - val_accuracy: 0.9752\n",
            "Epoch 137/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 137: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9756 - val_accuracy: 0.9752\n",
            "Epoch 138/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 138: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9756 - val_accuracy: 0.9752\n",
            "Epoch 139/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 139: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.0075e-08 - accuracy: 1.0000 - val_loss: 0.9759 - val_accuracy: 0.9752\n",
            "Epoch 140/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 2.6491e-09 - accuracy: 1.0000\n",
            "Epoch 140: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.4040e-08 - accuracy: 1.0000 - val_loss: 0.9815 - val_accuracy: 0.9752\n",
            "Epoch 141/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0041 - accuracy: 0.9974    \n",
            "Epoch 141: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.9979 - val_loss: 0.9864 - val_accuracy: 0.9752\n",
            "Epoch 142/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 1.8046e-07 - accuracy: 1.0000\n",
            "Epoch 142: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3507e-07 - accuracy: 1.0000 - val_loss: 1.0025 - val_accuracy: 0.9752\n",
            "Epoch 143/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 143: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 7.4351e-10 - accuracy: 1.0000 - val_loss: 1.0050 - val_accuracy: 0.9752\n",
            "Epoch 144/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 144: val_loss did not improve from 0.37166\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.8673 - val_accuracy: 0.9752\n",
            "Epoch 145/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0515 - accuracy: 0.9972    \n",
            "Epoch 145: val_loss improved from 0.37166 to 0.20339, saving model to ./audio_classification.hdf5\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0385 - accuracy: 0.9979 - val_loss: 0.2034 - val_accuracy: 0.9835\n",
            "Epoch 146/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0651 - accuracy: 0.9972    \n",
            "Epoch 146: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0487 - accuracy: 0.9979 - val_loss: 0.5097 - val_accuracy: 0.9835\n",
            "Epoch 147/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 1.5611e-08 - accuracy: 1.0000\n",
            "Epoch 147: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0905e-08 - accuracy: 1.0000 - val_loss: 0.6106 - val_accuracy: 0.9752\n",
            "Epoch 148/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 5.9956e-06 - accuracy: 1.0000\n",
            "Epoch 148: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2830e-04 - accuracy: 1.0000 - val_loss: 0.7042 - val_accuracy: 0.9669\n",
            "Epoch 149/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0851 - accuracy: 0.9972    \n",
            "Epoch 149: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0637 - accuracy: 0.9979 - val_loss: 0.2152 - val_accuracy: 0.9835\n",
            "Epoch 150/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.1937 - accuracy: 0.9944    \n",
            "Epoch 150: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.1449 - accuracy: 0.9958 - val_loss: 0.7579 - val_accuracy: 0.9752\n",
            "Epoch 151/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 9.4696e-05 - accuracy: 1.0000\n",
            "Epoch 151: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 6.9515e-05 - accuracy: 1.0000 - val_loss: 1.1014 - val_accuracy: 0.9587\n",
            "Epoch 152/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0035 - accuracy: 0.9972    \n",
            "Epoch 152: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 0.9979 - val_loss: 1.1694 - val_accuracy: 0.9587\n",
            "Epoch 153/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 2.0240e-07 - accuracy: 1.0000\n",
            "Epoch 153: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.7782e-07 - accuracy: 1.0000 - val_loss: 1.1918 - val_accuracy: 0.9587\n",
            "Epoch 154/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0485 - accuracy: 0.9974    \n",
            "Epoch 154: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0388 - accuracy: 0.9979 - val_loss: 1.2034 - val_accuracy: 0.9587\n",
            "Epoch 155/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 1.0928e-08 - accuracy: 1.0000\n",
            "Epoch 155: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 8.1786e-09 - accuracy: 1.0000 - val_loss: 1.0396 - val_accuracy: 0.9587\n",
            "Epoch 156/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 1.0872e-06 - accuracy: 1.0000\n",
            "Epoch 156: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0830 - accuracy: 0.9979 - val_loss: 0.6237 - val_accuracy: 0.9752\n",
            "Epoch 157/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 1.8626e-09 - accuracy: 1.0000\n",
            "Epoch 157: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 7.0028e-05 - accuracy: 1.0000 - val_loss: 0.3191 - val_accuracy: 0.9835\n",
            "Epoch 158/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000    \n",
            "Epoch 158: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.7277 - val_accuracy: 0.9752\n",
            "Epoch 159/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 6.2183e-07 - accuracy: 1.0000\n",
            "Epoch 159: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 7.1322e-07 - accuracy: 1.0000 - val_loss: 0.8357 - val_accuracy: 0.9752\n",
            "Epoch 160/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 1.8576e-07 - accuracy: 1.0000\n",
            "Epoch 160: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.3903e-07 - accuracy: 1.0000 - val_loss: 0.8181 - val_accuracy: 0.9752\n",
            "Epoch 161/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.1781 - accuracy: 0.9972    \n",
            "Epoch 161: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.1374 - accuracy: 0.9958 - val_loss: 0.2682 - val_accuracy: 0.9917\n",
            "Epoch 162/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0388 - accuracy: 0.9944    \n",
            "Epoch 162: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0291 - accuracy: 0.9958 - val_loss: 0.4577 - val_accuracy: 0.9835\n",
            "Epoch 163/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000    \n",
            "Epoch 163: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0219 - accuracy: 0.9979 - val_loss: 0.4673 - val_accuracy: 0.9835\n",
            "Epoch 164/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 1.1269e-07 - accuracy: 1.0000\n",
            "Epoch 164: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 8.9964e-08 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.9835\n",
            "Epoch 165/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 3.4294e-04 - accuracy: 1.0000\n",
            "Epoch 165: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.6221e-04 - accuracy: 1.0000 - val_loss: 0.5611 - val_accuracy: 0.9835\n",
            "Epoch 166/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0052 - accuracy: 0.9974    \n",
            "Epoch 166: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 0.9979 - val_loss: 0.7338 - val_accuracy: 0.9752\n",
            "Epoch 167/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 7.2179e-05 - accuracy: 1.0000\n",
            "Epoch 167: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0431e-04 - accuracy: 1.0000 - val_loss: 0.8049 - val_accuracy: 0.9752\n",
            "Epoch 168/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 3.5431e-08 - accuracy: 1.0000\n",
            "Epoch 168: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.6518e-08 - accuracy: 1.0000 - val_loss: 0.8443 - val_accuracy: 0.9752\n",
            "Epoch 169/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 2.3594e-04 - accuracy: 1.0000\n",
            "Epoch 169: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.8841e-04 - accuracy: 1.0000 - val_loss: 0.8602 - val_accuracy: 0.9752\n",
            "Epoch 170/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 8.0971e-06 - accuracy: 1.0000\n",
            "Epoch 170: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 6.0602e-06 - accuracy: 1.0000 - val_loss: 0.8746 - val_accuracy: 0.9752\n",
            "Epoch 171/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 1.8220e-06 - accuracy: 1.0000\n",
            "Epoch 171: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3636e-06 - accuracy: 1.0000 - val_loss: 0.8847 - val_accuracy: 0.9752\n",
            "Epoch 172/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 3.1138e-05 - accuracy: 1.0000\n",
            "Epoch 172: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.4859e-05 - accuracy: 1.0000 - val_loss: 0.9653 - val_accuracy: 0.9752\n",
            "Epoch 173/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 173: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3631e-08 - accuracy: 1.0000 - val_loss: 0.9764 - val_accuracy: 0.9752\n",
            "Epoch 174/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 1.0422e-04 - accuracy: 1.0000\n",
            "Epoch 174: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 8.3267e-05 - accuracy: 1.0000 - val_loss: 1.0000 - val_accuracy: 0.9752\n",
            "Epoch 175/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 4.3462e-09 - accuracy: 1.0000\n",
            "Epoch 175: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.1858e-07 - accuracy: 1.0000 - val_loss: 1.0031 - val_accuracy: 0.9752\n",
            "Epoch 176/500\n",
            "18/21 [========================>.....] - ETA: 0s - loss: 1.0127e-07 - accuracy: 1.0000\n",
            "Epoch 176: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 9.0954e-08 - accuracy: 1.0000 - val_loss: 1.0107 - val_accuracy: 0.9752\n",
            "Epoch 177/500\n",
            "11/21 [==============>...............] - ETA: 0s - loss: 1.3547e-09 - accuracy: 1.0000\n",
            "Epoch 177: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 1.0459e-07 - accuracy: 1.0000 - val_loss: 1.0141 - val_accuracy: 0.9752\n",
            "Epoch 178/500\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 7.9479e-04 - accuracy: 1.0000\n",
            "Epoch 178: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 7.5349e-04 - accuracy: 1.0000 - val_loss: 0.9777 - val_accuracy: 0.9752\n",
            "Epoch 179/500\n",
            "11/21 [==============>...............] - ETA: 0s - loss: 7.9292e-05 - accuracy: 1.0000\n",
            "Epoch 179: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 4.3520e-05 - accuracy: 1.0000 - val_loss: 0.9935 - val_accuracy: 0.9752\n",
            "Epoch 180/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 1.2424e-04 - accuracy: 1.0000\n",
            "Epoch 180: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 7.4420e-05 - accuracy: 1.0000 - val_loss: 1.2155 - val_accuracy: 0.9752\n",
            "Epoch 181/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 2.4071e-08 - accuracy: 1.0000\n",
            "Epoch 181: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.5614e-08 - accuracy: 1.0000 - val_loss: 1.2372 - val_accuracy: 0.9752\n",
            "Epoch 182/500\n",
            "11/21 [==============>...............] - ETA: 0s - loss: 9.4825e-09 - accuracy: 1.0000\n",
            "Epoch 182: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 4.2857e-06 - accuracy: 1.0000 - val_loss: 1.2410 - val_accuracy: 0.9752\n",
            "Epoch 183/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0716 - accuracy: 0.9936    \n",
            "Epoch 183: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0465 - accuracy: 0.9958 - val_loss: 0.6146 - val_accuracy: 0.9835\n",
            "Epoch 184/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 9.8724e-04 - accuracy: 1.0000\n",
            "Epoch 184: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7496 - val_accuracy: 0.9835\n",
            "Epoch 185/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 3.1659e-06 - accuracy: 1.0000\n",
            "Epoch 185: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 2.0188e-06 - accuracy: 1.0000 - val_loss: 0.7817 - val_accuracy: 0.9835\n",
            "Epoch 186/500\n",
            "10/21 [=============>................] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000    \n",
            "Epoch 186: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 0.9336 - val_accuracy: 0.9752\n",
            "Epoch 187/500\n",
            "21/21 [==============================] - ETA: 0s - loss: 2.0348e-06 - accuracy: 1.0000\n",
            "Epoch 187: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 2.0348e-06 - accuracy: 1.0000 - val_loss: 1.0330 - val_accuracy: 0.9752\n",
            "Epoch 188/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 2.9079e-04 - accuracy: 1.0000\n",
            "Epoch 188: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.8561e-04 - accuracy: 1.0000 - val_loss: 1.0474 - val_accuracy: 0.9669\n",
            "Epoch 189/500\n",
            "11/21 [==============>...............] - ETA: 0s - loss: 4.4527e-06 - accuracy: 1.0000\n",
            "Epoch 189: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.0106 - accuracy: 0.9979 - val_loss: 0.9261 - val_accuracy: 0.9752\n",
            "Epoch 190/500\n",
            "11/21 [==============>...............] - ETA: 0s - loss: 0.0448 - accuracy: 0.9962    \n",
            "Epoch 190: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0246 - accuracy: 0.9979 - val_loss: 1.4746 - val_accuracy: 0.9752\n",
            "Epoch 191/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 6.8775e-09 - accuracy: 1.0000\n",
            "Epoch 191: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 4.4611e-09 - accuracy: 1.0000 - val_loss: 1.7072 - val_accuracy: 0.9752\n",
            "Epoch 192/500\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0023 - accuracy: 0.9979\n",
            "Epoch 192: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.0023 - accuracy: 0.9979 - val_loss: 1.5377 - val_accuracy: 0.9752\n",
            "Epoch 193/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 1.1559e-05 - accuracy: 1.0000\n",
            "Epoch 193: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 6.9217e-06 - accuracy: 1.0000 - val_loss: 1.4993 - val_accuracy: 0.9752\n",
            "Epoch 194/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 1.5696e-04 - accuracy: 1.0000\n",
            "Epoch 194: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0192 - accuracy: 0.9979 - val_loss: 1.2281 - val_accuracy: 0.9752\n",
            "Epoch 195/500\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    \n",
            "Epoch 195: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 9.9581e-04 - accuracy: 1.0000 - val_loss: 0.9833 - val_accuracy: 0.9752\n",
            "Epoch 196/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 6.5028e-04 - accuracy: 1.0000\n",
            "Epoch 196: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 3.8983e-04 - accuracy: 1.0000 - val_loss: 1.2919 - val_accuracy: 0.9752\n",
            "Epoch 197/500\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.0333 - accuracy: 0.9978    \n",
            "Epoch 197: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.0316 - accuracy: 0.9979 - val_loss: 1.1335 - val_accuracy: 0.9752\n",
            "Epoch 198/500\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.0230 - accuracy: 0.9956\n",
            "Epoch 198: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.0218 - accuracy: 0.9958 - val_loss: 0.8365 - val_accuracy: 0.9752\n",
            "Epoch 199/500\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 2.5262e-05 - accuracy: 1.0000\n",
            "Epoch 199: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 11ms/step - loss: 2.3949e-05 - accuracy: 1.0000 - val_loss: 1.4885 - val_accuracy: 0.9752\n",
            "Epoch 200/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 2.8161e-06 - accuracy: 1.0000\n",
            "Epoch 200: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.2496e-06 - accuracy: 1.0000 - val_loss: 1.5858 - val_accuracy: 0.9752\n",
            "Epoch 201/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 1.6355e-05 - accuracy: 1.0000\n",
            "Epoch 201: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3057e-05 - accuracy: 1.0000 - val_loss: 1.6007 - val_accuracy: 0.9752\n",
            "Epoch 202/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 6.0442e-04 - accuracy: 1.0000\n",
            "Epoch 202: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0330 - accuracy: 0.9979 - val_loss: 1.1105 - val_accuracy: 0.9752\n",
            "Epoch 203/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0214 - accuracy: 0.9974    \n",
            "Epoch 203: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0171 - accuracy: 0.9979 - val_loss: 1.6405 - val_accuracy: 0.9587\n",
            "Epoch 204/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0441 - accuracy: 0.9948\n",
            "Epoch 204: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0352 - accuracy: 0.9958 - val_loss: 2.0116 - val_accuracy: 0.9587\n",
            "Epoch 205/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0187 - accuracy: 0.9974    \n",
            "Epoch 205: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0157 - accuracy: 0.9979 - val_loss: 1.6739 - val_accuracy: 0.9587\n",
            "Epoch 206/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 3.6425e-09 - accuracy: 1.0000\n",
            "Epoch 206: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.7014e-05 - accuracy: 1.0000 - val_loss: 1.8541 - val_accuracy: 0.9587\n",
            "Epoch 207/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 3.8208e-10 - accuracy: 1.0000\n",
            "Epoch 207: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.4784e-10 - accuracy: 1.0000 - val_loss: 1.8842 - val_accuracy: 0.9587\n",
            "Epoch 208/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0652 - accuracy: 0.9968    \n",
            "Epoch 208: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0423 - accuracy: 0.9979 - val_loss: 1.2505 - val_accuracy: 0.9752\n",
            "Epoch 209/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 1.4880e-04 - accuracy: 1.0000\n",
            "Epoch 209: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1137e-04 - accuracy: 1.0000 - val_loss: 1.2015 - val_accuracy: 0.9752\n",
            "Epoch 210/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0042 - accuracy: 0.9972    \n",
            "Epoch 210: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 0.9979 - val_loss: 1.2442 - val_accuracy: 0.9752\n",
            "Epoch 211/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 4.4762e-07 - accuracy: 1.0000\n",
            "Epoch 211: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.5735e-07 - accuracy: 1.0000 - val_loss: 1.2751 - val_accuracy: 0.9752\n",
            "Epoch 212/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 2.9802e-08 - accuracy: 1.0000\n",
            "Epoch 212: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.3792e-08 - accuracy: 1.0000 - val_loss: 1.2788 - val_accuracy: 0.9752\n",
            "Epoch 213/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 213: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2793 - val_accuracy: 0.9752\n",
            "Epoch 214/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 1.6557e-09 - accuracy: 1.0000\n",
            "Epoch 214: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2392e-09 - accuracy: 1.0000 - val_loss: 1.2793 - val_accuracy: 0.9752\n",
            "Epoch 215/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 215: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2793 - val_accuracy: 0.9752\n",
            "Epoch 216/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 216: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2793 - val_accuracy: 0.9752\n",
            "Epoch 217/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 1.8755e-05 - accuracy: 1.0000\n",
            "Epoch 217: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4037e-05 - accuracy: 1.0000 - val_loss: 1.2876 - val_accuracy: 0.9752\n",
            "Epoch 218/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 1.6900e-05 - accuracy: 1.0000\n",
            "Epoch 218: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.4547e-05 - accuracy: 1.0000 - val_loss: 1.2855 - val_accuracy: 0.9752\n",
            "Epoch 219/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 219: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2871 - val_accuracy: 0.9752\n",
            "Epoch 220/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 1.3543e-07 - accuracy: 1.0000\n",
            "Epoch 220: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.3017e-05 - accuracy: 1.0000 - val_loss: 1.2919 - val_accuracy: 0.9752\n",
            "Epoch 221/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 8.8954e-05 - accuracy: 1.0000\n",
            "Epoch 221: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 6.6577e-05 - accuracy: 1.0000 - val_loss: 1.3186 - val_accuracy: 0.9752\n",
            "Epoch 222/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0134 - accuracy: 0.9972    \n",
            "Epoch 222: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 2.0773 - val_accuracy: 0.9587\n",
            "Epoch 223/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 223: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.3762 - val_accuracy: 0.9587\n",
            "Epoch 224/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000    \n",
            "Epoch 224: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.4063 - val_accuracy: 0.9587\n",
            "Epoch 225/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 3.3114e-10 - accuracy: 1.0000\n",
            "Epoch 225: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.4784e-10 - accuracy: 1.0000 - val_loss: 2.4095 - val_accuracy: 0.9587\n",
            "Epoch 226/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0060 - accuracy: 0.9974\n",
            "Epoch 226: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 0.9979 - val_loss: 2.2960 - val_accuracy: 0.9669\n",
            "Epoch 227/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 1.3212e-07 - accuracy: 1.0000\n",
            "Epoch 227: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 9.8884e-08 - accuracy: 1.0000 - val_loss: 2.2879 - val_accuracy: 0.9669\n",
            "Epoch 228/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 2.6742e-04 - accuracy: 1.0000\n",
            "Epoch 228: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.0015e-04 - accuracy: 1.0000 - val_loss: 2.2576 - val_accuracy: 0.9669\n",
            "Epoch 229/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 229: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2516 - val_accuracy: 0.9669\n",
            "Epoch 230/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 1.0644e-09 - accuracy: 1.0000\n",
            "Epoch 230: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 7.4351e-10 - accuracy: 1.0000 - val_loss: 2.2509 - val_accuracy: 0.9669\n",
            "Epoch 231/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 231: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2509 - val_accuracy: 0.9669\n",
            "Epoch 232/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 232: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2508 - val_accuracy: 0.9669\n",
            "Epoch 233/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 1.4280e-08 - accuracy: 1.0000\n",
            "Epoch 233: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.1400e-08 - accuracy: 1.0000 - val_loss: 2.2512 - val_accuracy: 0.9669\n",
            "Epoch 234/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 234: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2515 - val_accuracy: 0.9669\n",
            "Epoch 235/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 5.1686e-07 - accuracy: 1.0000\n",
            "Epoch 235: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 3.8684e-07 - accuracy: 1.0000 - val_loss: 2.2519 - val_accuracy: 0.9669\n",
            "Epoch 236/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 1.1885e-07 - accuracy: 1.0000\n",
            "Epoch 236: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.5709e-04 - accuracy: 1.0000 - val_loss: 2.2854 - val_accuracy: 0.9669\n",
            "Epoch 237/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0090 - accuracy: 0.9972    \n",
            "Epoch 237: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 2.4795 - val_accuracy: 0.9669\n",
            "Epoch 238/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 3.6425e-08 - accuracy: 1.0000\n",
            "Epoch 238: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.7262e-08 - accuracy: 1.0000 - val_loss: 2.5342 - val_accuracy: 0.9669\n",
            "Epoch 239/500\n",
            "11/21 [==============>...............] - ETA: 0s - loss: 3.7479e-08 - accuracy: 1.0000\n",
            "Epoch 239: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.0570e-08 - accuracy: 1.0000 - val_loss: 2.5406 - val_accuracy: 0.9669\n",
            "Epoch 240/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 3.3114e-10 - accuracy: 1.0000\n",
            "Epoch 240: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.4784e-10 - accuracy: 1.0000 - val_loss: 2.5413 - val_accuracy: 0.9669\n",
            "Epoch 241/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 6.2072e-05 - accuracy: 1.0000\n",
            "Epoch 241: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 4.6457e-05 - accuracy: 1.0000 - val_loss: 2.5286 - val_accuracy: 0.9669\n",
            "Epoch 242/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 1.6275e-05 - accuracy: 1.0000\n",
            "Epoch 242: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2993e-05 - accuracy: 1.0000 - val_loss: 2.5265 - val_accuracy: 0.9669\n",
            "Epoch 243/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 1.8626e-09 - accuracy: 1.0000\n",
            "Epoch 243: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2929e-06 - accuracy: 1.0000 - val_loss: 2.5278 - val_accuracy: 0.9669\n",
            "Epoch 244/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 1.2418e-09 - accuracy: 1.0000\n",
            "Epoch 244: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 9.9135e-10 - accuracy: 1.0000 - val_loss: 2.5278 - val_accuracy: 0.9669\n",
            "Epoch 245/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 6.5193e-09 - accuracy: 1.0000\n",
            "Epoch 245: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 5.2046e-09 - accuracy: 1.0000 - val_loss: 2.5278 - val_accuracy: 0.9669\n",
            "Epoch 246/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000    \n",
            "Epoch 246: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.5903 - val_accuracy: 0.9669\n",
            "Epoch 247/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 7.6416e-09 - accuracy: 1.0000\n",
            "Epoch 247: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4585e-04 - accuracy: 1.0000 - val_loss: 2.6049 - val_accuracy: 0.9669\n",
            "Epoch 248/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 248: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.6200 - val_accuracy: 0.9669\n",
            "Epoch 249/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 3.5479e-10 - accuracy: 1.0000\n",
            "Epoch 249: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 6.3586e-07 - accuracy: 1.0000 - val_loss: 2.6222 - val_accuracy: 0.9669\n",
            "Epoch 250/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 1.2395e-06 - accuracy: 1.0000\n",
            "Epoch 250: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3014e-06 - accuracy: 1.0000 - val_loss: 2.6275 - val_accuracy: 0.9669\n",
            "Epoch 251/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 2.3180e-09 - accuracy: 1.0000\n",
            "Epoch 251: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.3049e-08 - accuracy: 1.0000 - val_loss: 2.6337 - val_accuracy: 0.9669\n",
            "Epoch 252/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 2.1980e-05 - accuracy: 1.0000\n",
            "Epoch 252: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.5354e-05 - accuracy: 1.0000 - val_loss: 2.6326 - val_accuracy: 0.9669\n",
            "Epoch 253/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 1.9868e-09 - accuracy: 1.0000\n",
            "Epoch 253: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4870e-09 - accuracy: 1.0000 - val_loss: 2.6325 - val_accuracy: 0.9669\n",
            "Epoch 254/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0058 - accuracy: 0.9974    \n",
            "Epoch 254: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 0.9979 - val_loss: 1.5294 - val_accuracy: 0.9752\n",
            "Epoch 255/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 2.0719e-07 - accuracy: 1.0000\n",
            "Epoch 255: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0484 - accuracy: 0.9958 - val_loss: 2.4582 - val_accuracy: 0.9752\n",
            "Epoch 256/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 2.4900e-06 - accuracy: 1.0000\n",
            "Epoch 256: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.8636e-06 - accuracy: 1.0000 - val_loss: 3.7528 - val_accuracy: 0.9587\n",
            "Epoch 257/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0977 - accuracy: 0.9972    \n",
            "Epoch 257: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0731 - accuracy: 0.9979 - val_loss: 2.3434 - val_accuracy: 0.9669\n",
            "Epoch 258/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 1.9210e-05 - accuracy: 1.0000\n",
            "Epoch 258: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3419e-05 - accuracy: 1.0000 - val_loss: 2.1765 - val_accuracy: 0.9752\n",
            "Epoch 259/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0212 - accuracy: 0.9972    \n",
            "Epoch 259: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0159 - accuracy: 0.9979 - val_loss: 1.6524 - val_accuracy: 0.9752\n",
            "Epoch 260/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 3.7545e-05 - accuracy: 1.0000\n",
            "Epoch 260: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0044 - accuracy: 0.9979 - val_loss: 1.5791 - val_accuracy: 0.9752\n",
            "Epoch 261/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 1.6444e-04 - accuracy: 1.0000\n",
            "Epoch 261: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1501e-04 - accuracy: 1.0000 - val_loss: 1.7091 - val_accuracy: 0.9752\n",
            "Epoch 262/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 1.8212e-08 - accuracy: 1.0000\n",
            "Epoch 262: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3631e-08 - accuracy: 1.0000 - val_loss: 1.7247 - val_accuracy: 0.9752\n",
            "Epoch 263/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 3.3699e-05 - accuracy: 1.0000\n",
            "Epoch 263: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.3540e-05 - accuracy: 1.0000 - val_loss: 1.7331 - val_accuracy: 0.9752\n",
            "Epoch 264/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 7.0958e-10 - accuracy: 1.0000\n",
            "Epoch 264: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 9.9135e-10 - accuracy: 1.0000 - val_loss: 1.7365 - val_accuracy: 0.9752\n",
            "Epoch 265/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 5.0830e-04 - accuracy: 1.0000\n",
            "Epoch 265: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.8043e-04 - accuracy: 1.0000 - val_loss: 1.5650 - val_accuracy: 0.9752\n",
            "Epoch 266/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 2.0530e-08 - accuracy: 1.0000\n",
            "Epoch 266: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 7.3854e-08 - accuracy: 1.0000 - val_loss: 1.4635 - val_accuracy: 0.9752\n",
            "Epoch 267/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0069 - accuracy: 0.9972    \n",
            "Epoch 267: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.9979 - val_loss: 1.6598 - val_accuracy: 0.9752\n",
            "Epoch 268/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 2.8274e-08 - accuracy: 1.0000\n",
            "Epoch 268: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.8340e-08 - accuracy: 1.0000 - val_loss: 1.7163 - val_accuracy: 0.9752\n",
            "Epoch 269/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 1.8891e-04 - accuracy: 1.0000\n",
            "Epoch 269: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4140e-04 - accuracy: 1.0000 - val_loss: 1.7085 - val_accuracy: 0.9752\n",
            "Epoch 270/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 7.3053e-04 - accuracy: 1.0000\n",
            "Epoch 270: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4.7386e-04 - accuracy: 1.0000 - val_loss: 1.7096 - val_accuracy: 0.9752\n",
            "Epoch 271/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 2.4477e-05 - accuracy: 1.0000\n",
            "Epoch 271: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.8319e-05 - accuracy: 1.0000 - val_loss: 1.7188 - val_accuracy: 0.9752\n",
            "Epoch 272/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 4.3994e-08 - accuracy: 1.0000\n",
            "Epoch 272: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.5014e-05 - accuracy: 1.0000 - val_loss: 1.7260 - val_accuracy: 0.9752\n",
            "Epoch 273/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 273: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 5.3402e-04 - accuracy: 1.0000 - val_loss: 1.7318 - val_accuracy: 0.9752\n",
            "Epoch 274/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 3.3114e-09 - accuracy: 1.0000\n",
            "Epoch 274: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.7262e-09 - accuracy: 1.0000 - val_loss: 1.7347 - val_accuracy: 0.9752\n",
            "Epoch 275/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 1.9503e-07 - accuracy: 1.0000\n",
            "Epoch 275: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.3337e-06 - accuracy: 1.0000 - val_loss: 1.7352 - val_accuracy: 0.9752\n",
            "Epoch 276/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 2.7153e-08 - accuracy: 1.0000\n",
            "Epoch 276: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 2.0323e-08 - accuracy: 1.0000 - val_loss: 1.7341 - val_accuracy: 0.9752\n",
            "Epoch 277/500\n",
            "21/21 [==============================] - ETA: 0s - loss: 5.0062e-08 - accuracy: 1.0000\n",
            "Epoch 277: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 5.0062e-08 - accuracy: 1.0000 - val_loss: 1.7344 - val_accuracy: 0.9752\n",
            "Epoch 278/500\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 2.3528e-09 - accuracy: 1.0000\n",
            "Epoch 278: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 2.2305e-09 - accuracy: 1.0000 - val_loss: 1.7345 - val_accuracy: 0.9752\n",
            "Epoch 279/500\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 8.3727e-05 - accuracy: 1.0000\n",
            "Epoch 279: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 7.9376e-05 - accuracy: 1.0000 - val_loss: 1.7457 - val_accuracy: 0.9752\n",
            "Epoch 280/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 1.1052e-07 - accuracy: 1.0000\n",
            "Epoch 280: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 1.9058e-07 - accuracy: 1.0000 - val_loss: 1.7500 - val_accuracy: 0.9752\n",
            "Epoch 281/500\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 8.9407e-09 - accuracy: 1.0000\n",
            "Epoch 281: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 8.9221e-09 - accuracy: 1.0000 - val_loss: 1.7473 - val_accuracy: 0.9752\n",
            "Epoch 282/500\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 1.6143e-07 - accuracy: 1.0000\n",
            "Epoch 282: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 1.6109e-07 - accuracy: 1.0000 - val_loss: 1.7475 - val_accuracy: 0.9752\n",
            "Epoch 283/500\n",
            "11/21 [==============>...............] - ETA: 0s - loss: 5.4651e-05 - accuracy: 1.0000\n",
            "Epoch 283: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 2.9995e-05 - accuracy: 1.0000 - val_loss: 1.7485 - val_accuracy: 0.9752\n",
            "Epoch 284/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 1.8582e-05 - accuracy: 1.0000\n",
            "Epoch 284: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.2053e-05 - accuracy: 1.0000 - val_loss: 1.7522 - val_accuracy: 0.9752\n",
            "Epoch 285/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 2.4368e-04 - accuracy: 1.0000\n",
            "Epoch 285: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.4603e-04 - accuracy: 1.0000 - val_loss: 1.8403 - val_accuracy: 0.9752\n",
            "Epoch 286/500\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9979\n",
            "Epoch 286: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.0023 - accuracy: 0.9979 - val_loss: 1.9369 - val_accuracy: 0.9752\n",
            "Epoch 287/500\n",
            "18/21 [========================>.....] - ETA: 0s - loss: 1.3052e-07 - accuracy: 1.0000\n",
            "Epoch 287: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 1.1722e-07 - accuracy: 1.0000 - val_loss: 1.9661 - val_accuracy: 0.9752\n",
            "Epoch 288/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 0.0025 - accuracy: 0.9975\n",
            "Epoch 288: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.9979 - val_loss: 1.9903 - val_accuracy: 0.9752\n",
            "Epoch 289/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 3.4329e-05 - accuracy: 1.0000\n",
            "Epoch 289: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 2.0555e-05 - accuracy: 1.0000 - val_loss: 2.0068 - val_accuracy: 0.9752\n",
            "Epoch 290/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 1.2418e-09 - accuracy: 1.0000\n",
            "Epoch 290: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 7.4351e-10 - accuracy: 1.0000 - val_loss: 2.0086 - val_accuracy: 0.9752\n",
            "Epoch 291/500\n",
            "18/21 [========================>.....] - ETA: 0s - loss: 4.3384e-05 - accuracy: 1.0000\n",
            "Epoch 291: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 3.8965e-05 - accuracy: 1.0000 - val_loss: 2.0072 - val_accuracy: 0.9752\n",
            "Epoch 292/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 4.9670e-09 - accuracy: 1.0000\n",
            "Epoch 292: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 4.7089e-09 - accuracy: 1.0000 - val_loss: 2.0243 - val_accuracy: 0.9752\n",
            "Epoch 293/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 9.9341e-09 - accuracy: 1.0000\n",
            "Epoch 293: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 7.4351e-09 - accuracy: 1.0000 - val_loss: 2.0297 - val_accuracy: 0.9752\n",
            "Epoch 294/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0236 - accuracy: 0.9972    \n",
            "Epoch 294: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0176 - accuracy: 0.9979 - val_loss: 2.1713 - val_accuracy: 0.9752\n",
            "Epoch 295/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000    \n",
            "Epoch 295: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.8689 - val_accuracy: 0.9752\n",
            "Epoch 296/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 296: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7805 - val_accuracy: 0.9752\n",
            "Epoch 297/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 297: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.4784e-10 - accuracy: 1.0000 - val_loss: 1.7702 - val_accuracy: 0.9752\n",
            "Epoch 298/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 9.4357e-04 - accuracy: 1.0000\n",
            "Epoch 298: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 7.0620e-04 - accuracy: 1.0000 - val_loss: 1.7864 - val_accuracy: 0.9752\n",
            "Epoch 299/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 299: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7999 - val_accuracy: 0.9752\n",
            "Epoch 300/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 4.8663e-06 - accuracy: 1.0000\n",
            "Epoch 300: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.4030e-06 - accuracy: 1.0000 - val_loss: 1.8168 - val_accuracy: 0.9752\n",
            "Epoch 301/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 7.1668e-06 - accuracy: 1.0000\n",
            "Epoch 301: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 5.3639e-06 - accuracy: 1.0000 - val_loss: 1.8070 - val_accuracy: 0.9752\n",
            "Epoch 302/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 1.7774e-07 - accuracy: 1.0000\n",
            "Epoch 302: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2416e-07 - accuracy: 1.0000 - val_loss: 1.7892 - val_accuracy: 0.9752\n",
            "Epoch 303/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 303: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7838 - val_accuracy: 0.9752\n",
            "Epoch 304/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 3.3114e-09 - accuracy: 1.0000\n",
            "Epoch 304: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.4784e-09 - accuracy: 1.0000 - val_loss: 1.7832 - val_accuracy: 0.9752\n",
            "Epoch 305/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 305: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 8.1210e-04 - accuracy: 1.0000 - val_loss: 1.7889 - val_accuracy: 0.9752\n",
            "Epoch 306/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 306: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7896 - val_accuracy: 0.9752\n",
            "Epoch 307/500\n",
            "11/21 [==============>...............] - ETA: 0s - loss: 8.5794e-09 - accuracy: 1.0000\n",
            "Epoch 307: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.2242e-04 - accuracy: 1.0000 - val_loss: 1.7938 - val_accuracy: 0.9752\n",
            "Epoch 308/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 308: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0136e-07 - accuracy: 1.0000 - val_loss: 1.8123 - val_accuracy: 0.9752\n",
            "Epoch 309/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 3.9205e-07 - accuracy: 1.0000\n",
            "Epoch 309: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.0854e-07 - accuracy: 1.0000 - val_loss: 1.8174 - val_accuracy: 0.9752\n",
            "Epoch 310/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 1.7881e-08 - accuracy: 1.0000\n",
            "Epoch 310: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3383e-08 - accuracy: 1.0000 - val_loss: 1.8195 - val_accuracy: 0.9752\n",
            "Epoch 311/500\n",
            "10/21 [=============>................] - ETA: 0s - loss: 3.2163e-05 - accuracy: 1.0000\n",
            "Epoch 311: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.6085e-05 - accuracy: 1.0000 - val_loss: 1.8301 - val_accuracy: 0.9752\n",
            "Epoch 312/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 1.1859e-04 - accuracy: 1.0000\n",
            "Epoch 312: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 8.2842e-05 - accuracy: 1.0000 - val_loss: 1.8689 - val_accuracy: 0.9752\n",
            "Epoch 313/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 313: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 2.4784e-10 - accuracy: 1.0000 - val_loss: 1.8776 - val_accuracy: 0.9752\n",
            "Epoch 314/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 6.6062e-05 - accuracy: 1.0000\n",
            "Epoch 314: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4.9443e-05 - accuracy: 1.0000 - val_loss: 1.8161 - val_accuracy: 0.9752\n",
            "Epoch 315/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 4.0255e-05 - accuracy: 1.0000\n",
            "Epoch 315: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.0128e-05 - accuracy: 1.0000 - val_loss: 1.7892 - val_accuracy: 0.9752\n",
            "Epoch 316/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000    \n",
            "Epoch 316: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 9.1226e-04 - accuracy: 1.0000 - val_loss: 1.7909 - val_accuracy: 0.9752\n",
            "Epoch 317/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 317: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4231e-05 - accuracy: 1.0000 - val_loss: 1.7860 - val_accuracy: 0.9752\n",
            "Epoch 318/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 318: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7787 - val_accuracy: 0.9752\n",
            "Epoch 319/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 3.9736e-09 - accuracy: 1.0000\n",
            "Epoch 319: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.9654e-09 - accuracy: 1.0000 - val_loss: 1.7790 - val_accuracy: 0.9752\n",
            "Epoch 320/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 3.3114e-09 - accuracy: 1.0000\n",
            "Epoch 320: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.4784e-09 - accuracy: 1.0000 - val_loss: 1.7790 - val_accuracy: 0.9752\n",
            "Epoch 321/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 321: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7790 - val_accuracy: 0.9752\n",
            "Epoch 322/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 6.6227e-10 - accuracy: 1.0000\n",
            "Epoch 322: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 5.6713e-05 - accuracy: 1.0000 - val_loss: 1.7656 - val_accuracy: 0.9752\n",
            "Epoch 323/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 1.2376e-07 - accuracy: 1.0000\n",
            "Epoch 323: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 7.4102e-08 - accuracy: 1.0000 - val_loss: 1.7212 - val_accuracy: 0.9752\n",
            "Epoch 324/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 1.6557e-09 - accuracy: 1.0000\n",
            "Epoch 324: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.2392e-09 - accuracy: 1.0000 - val_loss: 1.7165 - val_accuracy: 0.9752\n",
            "Epoch 325/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 325: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.2049e-05 - accuracy: 1.0000 - val_loss: 1.7193 - val_accuracy: 0.9752\n",
            "Epoch 326/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 6.7142e-05 - accuracy: 1.0000\n",
            "Epoch 326: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 5.5464e-04 - accuracy: 1.0000 - val_loss: 1.7352 - val_accuracy: 0.9752\n",
            "Epoch 327/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 327: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0919e-06 - accuracy: 1.0000 - val_loss: 1.7425 - val_accuracy: 0.9752\n",
            "Epoch 328/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 328: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 9.4919e-08 - accuracy: 1.0000 - val_loss: 1.7466 - val_accuracy: 0.9752\n",
            "Epoch 329/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 4.8710e-06 - accuracy: 1.0000\n",
            "Epoch 329: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.6456e-06 - accuracy: 1.0000 - val_loss: 1.7478 - val_accuracy: 0.9752\n",
            "Epoch 330/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 5.1080e-07 - accuracy: 1.0000\n",
            "Epoch 330: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.3133e-07 - accuracy: 1.0000 - val_loss: 1.7500 - val_accuracy: 0.9752\n",
            "Epoch 331/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 331: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7508 - val_accuracy: 0.9752\n",
            "Epoch 332/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 5.1444e-08 - accuracy: 1.0000\n",
            "Epoch 332: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.6184e-08 - accuracy: 1.0000 - val_loss: 1.7509 - val_accuracy: 0.9752\n",
            "Epoch 333/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 6.6227e-10 - accuracy: 1.0000\n",
            "Epoch 333: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 4.9567e-10 - accuracy: 1.0000 - val_loss: 1.7509 - val_accuracy: 0.9752\n",
            "Epoch 334/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 3.5479e-10 - accuracy: 1.0000\n",
            "Epoch 334: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.4784e-10 - accuracy: 1.0000 - val_loss: 1.7510 - val_accuracy: 0.9752\n",
            "Epoch 335/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 335: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.5540e-04 - accuracy: 1.0000 - val_loss: 1.7584 - val_accuracy: 0.9752\n",
            "Epoch 336/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 3.8315e-07 - accuracy: 1.0000\n",
            "Epoch 336: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.2713e-04 - accuracy: 1.0000 - val_loss: 1.8390 - val_accuracy: 0.9752\n",
            "Epoch 337/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 8.1600e-08 - accuracy: 1.0000\n",
            "Epoch 337: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 5.7002e-08 - accuracy: 1.0000 - val_loss: 1.9231 - val_accuracy: 0.9752\n",
            "Epoch 338/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000    \n",
            "Epoch 338: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.9666 - val_accuracy: 0.9752\n",
            "Epoch 339/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 3.6556e-05 - accuracy: 1.0000\n",
            "Epoch 339: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.5536e-05 - accuracy: 1.0000 - val_loss: 1.9898 - val_accuracy: 0.9752\n",
            "Epoch 340/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 340: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.4784e-10 - accuracy: 1.0000 - val_loss: 1.9945 - val_accuracy: 0.9752\n",
            "Epoch 341/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 2.0397e-06 - accuracy: 1.0000\n",
            "Epoch 341: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.5266e-06 - accuracy: 1.0000 - val_loss: 1.9954 - val_accuracy: 0.9752\n",
            "Epoch 342/500\n",
            "11/21 [==============>...............] - ETA: 0s - loss: 1.2957e-06 - accuracy: 1.0000\n",
            "Epoch 342: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 7.1117e-07 - accuracy: 1.0000 - val_loss: 1.9959 - val_accuracy: 0.9752\n",
            "Epoch 343/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 3.2782e-08 - accuracy: 1.0000\n",
            "Epoch 343: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.4908e-04 - accuracy: 1.0000 - val_loss: 1.9995 - val_accuracy: 0.9752\n",
            "Epoch 344/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 344: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0030 - val_accuracy: 0.9752\n",
            "Epoch 345/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 345: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0034 - val_accuracy: 0.9752\n",
            "Epoch 346/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 346: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0034 - val_accuracy: 0.9752\n",
            "Epoch 347/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 347: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 9.8141e-08 - accuracy: 1.0000 - val_loss: 2.0035 - val_accuracy: 0.9752\n",
            "Epoch 348/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 348: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1322e-04 - accuracy: 1.0000 - val_loss: 2.0212 - val_accuracy: 0.9752\n",
            "Epoch 349/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 9.5793e-09 - accuracy: 1.0000\n",
            "Epoch 349: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 6.6916e-09 - accuracy: 1.0000 - val_loss: 2.0912 - val_accuracy: 0.9752\n",
            "Epoch 350/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 1.5256e-08 - accuracy: 1.0000\n",
            "Epoch 350: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0657e-08 - accuracy: 1.0000 - val_loss: 2.0996 - val_accuracy: 0.9752\n",
            "Epoch 351/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 351: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.1006 - val_accuracy: 0.9752\n",
            "Epoch 352/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 352: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.1007 - val_accuracy: 0.9752\n",
            "Epoch 353/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 1.7138e-05 - accuracy: 1.0000\n",
            "Epoch 353: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2855e-05 - accuracy: 1.0000 - val_loss: 2.1276 - val_accuracy: 0.9752\n",
            "Epoch 354/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0247 - accuracy: 0.9968    \n",
            "Epoch 354: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0160 - accuracy: 0.9979 - val_loss: 1.5557 - val_accuracy: 0.9752\n",
            "Epoch 355/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 2.0729e-07 - accuracy: 1.0000\n",
            "Epoch 355: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 7.4590e-07 - accuracy: 1.0000 - val_loss: 1.4863 - val_accuracy: 0.9752\n",
            "Epoch 356/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0103 - accuracy: 0.9972    \n",
            "Epoch 356: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 2.5953 - val_accuracy: 0.9587\n",
            "Epoch 357/500\n",
            "11/21 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 357: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 8.1786e-09 - accuracy: 1.0000 - val_loss: 3.0114 - val_accuracy: 0.9587\n",
            "Epoch 358/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 1.0408e-04 - accuracy: 1.0000\n",
            "Epoch 358: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 7.2705e-05 - accuracy: 1.0000 - val_loss: 2.7836 - val_accuracy: 0.9587\n",
            "Epoch 359/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0496 - accuracy: 0.9968    \n",
            "Epoch 359: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0322 - accuracy: 0.9979 - val_loss: 1.1779 - val_accuracy: 0.9835\n",
            "Epoch 360/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 3.6543e-08 - accuracy: 1.0000\n",
            "Epoch 360: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 1.3927 - val_accuracy: 0.9752\n",
            "Epoch 361/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 361: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.8347 - val_accuracy: 0.9587\n",
            "Epoch 362/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 362: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1771e-05 - accuracy: 1.0000 - val_loss: 3.0699 - val_accuracy: 0.9587\n",
            "Epoch 363/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 7.8645e-09 - accuracy: 1.0000\n",
            "Epoch 363: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 4.7089e-09 - accuracy: 1.0000 - val_loss: 3.1062 - val_accuracy: 0.9587\n",
            "Epoch 364/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 364: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.1103 - val_accuracy: 0.9587\n",
            "Epoch 365/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 365: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.1107 - val_accuracy: 0.9587\n",
            "Epoch 366/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0241 - accuracy: 0.9940    \n",
            "Epoch 366: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0168 - accuracy: 0.9958 - val_loss: 1.1740 - val_accuracy: 0.9752\n",
            "Epoch 367/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0341 - accuracy: 0.9968    \n",
            "Epoch 367: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.0221 - accuracy: 0.9979 - val_loss: 1.1236 - val_accuracy: 0.9835\n",
            "Epoch 368/500\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0776 - accuracy: 0.9937\n",
            "Epoch 368: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.0774 - accuracy: 0.9938 - val_loss: 0.8540 - val_accuracy: 0.9917\n",
            "Epoch 369/500\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.1521 - accuracy: 0.9937\n",
            "Epoch 369: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.1518 - accuracy: 0.9938 - val_loss: 1.3711 - val_accuracy: 0.9669\n",
            "Epoch 370/500\n",
            "10/21 [=============>................] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000    \n",
            "Epoch 370: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.0992 - accuracy: 0.9979 - val_loss: 1.1036 - val_accuracy: 0.9752\n",
            "Epoch 371/500\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.0465 - accuracy: 0.9978    \n",
            "Epoch 371: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.0441 - accuracy: 0.9979 - val_loss: 0.8303 - val_accuracy: 0.9835\n",
            "Epoch 372/500\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 4.7839e-06 - accuracy: 1.0000\n",
            "Epoch 372: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 4.7740e-06 - accuracy: 1.0000 - val_loss: 0.7801 - val_accuracy: 0.9835\n",
            "Epoch 373/500\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.1354 - accuracy: 0.9937\n",
            "Epoch 373: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 11ms/step - loss: 0.1351 - accuracy: 0.9938 - val_loss: 2.0610 - val_accuracy: 0.9669\n",
            "Epoch 374/500\n",
            "11/21 [==============>...............] - ETA: 0s - loss: 0.0042 - accuracy: 0.9962    \n",
            "Epoch 374: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 0.9979 - val_loss: 1.9313 - val_accuracy: 0.9669\n",
            "Epoch 375/500\n",
            "21/21 [==============================] - ETA: 0s - loss: 2.4784e-10 - accuracy: 1.0000\n",
            "Epoch 375: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 2.4784e-10 - accuracy: 1.0000 - val_loss: 1.9074 - val_accuracy: 0.9669\n",
            "Epoch 376/500\n",
            "11/21 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 376: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 0.1719 - accuracy: 0.9979 - val_loss: 1.7888 - val_accuracy: 0.9669\n",
            "Epoch 377/500\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 377: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5865 - val_accuracy: 0.9669\n",
            "Epoch 378/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 7.3132e-07 - accuracy: 1.0000\n",
            "Epoch 378: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 4.3788e-07 - accuracy: 1.0000 - val_loss: 1.6032 - val_accuracy: 0.9669\n",
            "Epoch 379/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 0.1024 - accuracy: 0.9931    \n",
            "Epoch 379: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0613 - accuracy: 0.9958 - val_loss: 1.5421 - val_accuracy: 0.9752\n",
            "Epoch 380/500\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.0035 - accuracy: 0.9978\n",
            "Epoch 380: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 0.9979 - val_loss: 1.5270 - val_accuracy: 0.9752\n",
            "Epoch 381/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 381: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5239 - val_accuracy: 0.9752\n",
            "Epoch 382/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 4.6390e-04 - accuracy: 1.0000\n",
            "Epoch 382: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 2.7776e-04 - accuracy: 1.0000 - val_loss: 1.5288 - val_accuracy: 0.9752\n",
            "Epoch 383/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 1.3701e-07 - accuracy: 1.0000\n",
            "Epoch 383: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 8.1961e-05 - accuracy: 1.0000 - val_loss: 1.5254 - val_accuracy: 0.9752\n",
            "Epoch 384/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 384: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5226 - val_accuracy: 0.9752\n",
            "Epoch 385/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 0.0251 - accuracy: 0.9965    \n",
            "Epoch 385: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.0150 - accuracy: 0.9979 - val_loss: 0.7353 - val_accuracy: 0.9917\n",
            "Epoch 386/500\n",
            "16/21 [=====================>........] - ETA: 0s - loss: 1.6018e-07 - accuracy: 1.0000\n",
            "Epoch 386: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 1.2813e-07 - accuracy: 1.0000 - val_loss: 0.7276 - val_accuracy: 0.9917\n",
            "Epoch 387/500\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 387: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.7268 - val_accuracy: 0.9917\n",
            "Epoch 388/500\n",
            "18/21 [========================>.....] - ETA: 0s - loss: 5.5189e-10 - accuracy: 1.0000\n",
            "Epoch 388: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 4.9567e-10 - accuracy: 1.0000 - val_loss: 0.7267 - val_accuracy: 0.9917\n",
            "Epoch 389/500\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 7.4506e-10 - accuracy: 1.0000\n",
            "Epoch 389: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 7.4351e-10 - accuracy: 1.0000 - val_loss: 0.7267 - val_accuracy: 0.9917\n",
            "Epoch 390/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 0.0116 - accuracy: 0.9965    \n",
            "Epoch 390: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 1.0669 - val_accuracy: 0.9835\n",
            "Epoch 391/500\n",
            "18/21 [========================>.....] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 391: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.4573 - val_accuracy: 0.9752\n",
            "Epoch 392/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 392: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5020 - val_accuracy: 0.9752\n",
            "Epoch 393/500\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 7.6989e-09 - accuracy: 1.0000\n",
            "Epoch 393: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 7.6829e-09 - accuracy: 1.0000 - val_loss: 1.5068 - val_accuracy: 0.9752\n",
            "Epoch 394/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0078 - accuracy: 0.9970    \n",
            "Epoch 394: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 1.4998 - val_accuracy: 0.9752\n",
            "Epoch 395/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 2.1161e-06 - accuracy: 1.0000\n",
            "Epoch 395: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 1.5327 - val_accuracy: 0.9752\n",
            "Epoch 396/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 1.8812e-06 - accuracy: 1.0000\n",
            "Epoch 396: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 0.9979 - val_loss: 1.4977 - val_accuracy: 0.9752\n",
            "Epoch 397/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0021 - accuracy: 0.9970    \n",
            "Epoch 397: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 0.9979 - val_loss: 1.2178 - val_accuracy: 0.9752\n",
            "Epoch 398/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 5.9959e-08 - accuracy: 1.0000\n",
            "Epoch 398: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4.1884e-08 - accuracy: 1.0000 - val_loss: 1.1851 - val_accuracy: 0.9752\n",
            "Epoch 399/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0100 - accuracy: 0.9968    \n",
            "Epoch 399: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.9744 - val_accuracy: 0.9835\n",
            "Epoch 400/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 2.1287e-09 - accuracy: 1.0000\n",
            "Epoch 400: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1648e-08 - accuracy: 1.0000 - val_loss: 0.9153 - val_accuracy: 0.9835\n",
            "Epoch 401/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 1.4546e-08 - accuracy: 1.0000\n",
            "Epoch 401: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0161e-08 - accuracy: 1.0000 - val_loss: 0.9113 - val_accuracy: 0.9835\n",
            "Epoch 402/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 3.6364e-04 - accuracy: 1.0000\n",
            "Epoch 402: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.3588e-04 - accuracy: 1.0000 - val_loss: 0.9447 - val_accuracy: 0.9835\n",
            "Epoch 403/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 403: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 6.3057e-04 - accuracy: 1.0000 - val_loss: 0.9704 - val_accuracy: 0.9835\n",
            "Epoch 404/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 1.1831e-06 - accuracy: 1.0000\n",
            "Epoch 404: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 8.2644e-07 - accuracy: 1.0000 - val_loss: 1.0160 - val_accuracy: 0.9835\n",
            "Epoch 405/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 405: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.7262e-08 - accuracy: 1.0000 - val_loss: 1.0181 - val_accuracy: 0.9835\n",
            "Epoch 406/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 406: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0183 - val_accuracy: 0.9835\n",
            "Epoch 407/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 407: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1400e-08 - accuracy: 1.0000 - val_loss: 1.0184 - val_accuracy: 0.9835\n",
            "Epoch 408/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 4.1392e-10 - accuracy: 1.0000\n",
            "Epoch 408: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.4784e-10 - accuracy: 1.0000 - val_loss: 1.0184 - val_accuracy: 0.9835\n",
            "Epoch 409/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 9.0861e-05 - accuracy: 1.0000\n",
            "Epoch 409: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 6.3972e-05 - accuracy: 1.0000 - val_loss: 1.0575 - val_accuracy: 0.9752\n",
            "Epoch 410/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 410: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0642 - val_accuracy: 0.9752\n",
            "Epoch 411/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 9.9341e-09 - accuracy: 1.0000\n",
            "Epoch 411: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 8.4264e-09 - accuracy: 1.0000 - val_loss: 1.0650 - val_accuracy: 0.9752\n",
            "Epoch 412/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 1.7895e-05 - accuracy: 1.0000\n",
            "Epoch 412: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.3393e-05 - accuracy: 1.0000 - val_loss: 1.0770 - val_accuracy: 0.9752\n",
            "Epoch 413/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 413: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0790 - val_accuracy: 0.9752\n",
            "Epoch 414/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0888 - accuracy: 0.9968    \n",
            "Epoch 414: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0576 - accuracy: 0.9979 - val_loss: 0.9141 - val_accuracy: 0.9835\n",
            "Epoch 415/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 415: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.8476 - val_accuracy: 0.9835\n",
            "Epoch 416/500\n",
            "11/21 [==============>...............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 416: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.8406 - val_accuracy: 0.9835\n",
            "Epoch 417/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 8.6959e-06 - accuracy: 1.0000\n",
            "Epoch 417: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 5.2067e-06 - accuracy: 1.0000 - val_loss: 0.8446 - val_accuracy: 0.9835\n",
            "Epoch 418/500\n",
            "15/21 [====================>.........] - ETA: 0s - loss: 2.7153e-08 - accuracy: 1.0000\n",
            "Epoch 418: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.4784e-08 - accuracy: 1.0000 - val_loss: 0.8457 - val_accuracy: 0.9835\n",
            "Epoch 419/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 2.6099e-04 - accuracy: 1.0000\n",
            "Epoch 419: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.6929e-04 - accuracy: 1.0000 - val_loss: 0.8546 - val_accuracy: 0.9835\n",
            "Epoch 420/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 420: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.8571 - val_accuracy: 0.9835\n",
            "Epoch 421/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 421: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 5.1301e-08 - accuracy: 1.0000 - val_loss: 0.8579 - val_accuracy: 0.9835\n",
            "Epoch 422/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 422: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.8591 - val_accuracy: 0.9835\n",
            "Epoch 423/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 423: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.0322e-08 - accuracy: 1.0000 - val_loss: 0.8592 - val_accuracy: 0.9835\n",
            "Epoch 424/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 424: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4.2627e-08 - accuracy: 1.0000 - val_loss: 0.8593 - val_accuracy: 0.9835\n",
            "Epoch 425/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 425: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4.9567e-10 - accuracy: 1.0000 - val_loss: 0.8593 - val_accuracy: 0.9835\n",
            "Epoch 426/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 5.7650e-06 - accuracy: 1.0000\n",
            "Epoch 426: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.7412e-06 - accuracy: 1.0000 - val_loss: 0.8647 - val_accuracy: 0.9835\n",
            "Epoch 427/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 2.6746e-08 - accuracy: 1.0000\n",
            "Epoch 427: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 0.9979 - val_loss: 1.0226 - val_accuracy: 0.9752\n",
            "Epoch 428/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 3.7130e-04 - accuracy: 1.0000\n",
            "Epoch 428: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.4084e-04 - accuracy: 1.0000 - val_loss: 1.1226 - val_accuracy: 0.9752\n",
            "Epoch 429/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 1.5823e-07 - accuracy: 1.0000\n",
            "Epoch 429: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1053e-07 - accuracy: 1.0000 - val_loss: 1.1307 - val_accuracy: 0.9752\n",
            "Epoch 430/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 430: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1316 - val_accuracy: 0.9752\n",
            "Epoch 431/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 6.9246e-04 - accuracy: 1.0000\n",
            "Epoch 431: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4.4916e-04 - accuracy: 1.0000 - val_loss: 1.1357 - val_accuracy: 0.9752\n",
            "Epoch 432/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 4.1320e-04 - accuracy: 1.0000\n",
            "Epoch 432: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.6807e-04 - accuracy: 1.0000 - val_loss: 1.1419 - val_accuracy: 0.9752\n",
            "Epoch 433/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000    \n",
            "Epoch 433: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.1493 - val_accuracy: 0.9752\n",
            "Epoch 434/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 2.3307e-08 - accuracy: 1.0000\n",
            "Epoch 434: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.5118e-08 - accuracy: 1.0000 - val_loss: 1.1521 - val_accuracy: 0.9752\n",
            "Epoch 435/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 1.1058e-05 - accuracy: 1.0000\n",
            "Epoch 435: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 7.7243e-06 - accuracy: 1.0000 - val_loss: 1.1544 - val_accuracy: 0.9752\n",
            "Epoch 436/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 1.6675e-08 - accuracy: 1.0000\n",
            "Epoch 436: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.1648e-08 - accuracy: 1.0000 - val_loss: 1.1546 - val_accuracy: 0.9752\n",
            "Epoch 437/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 437: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0858 - accuracy: 0.9979 - val_loss: 0.8734 - val_accuracy: 0.9835\n",
            "Epoch 438/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 3.4845e-06 - accuracy: 1.0000\n",
            "Epoch 438: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.7099e-06 - accuracy: 1.0000 - val_loss: 0.6897 - val_accuracy: 0.9835\n",
            "Epoch 439/500\n",
            "11/21 [==============>...............] - ETA: 0s - loss: 2.1990e-07 - accuracy: 1.0000\n",
            "Epoch 439: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.2069e-07 - accuracy: 1.0000 - val_loss: 0.6725 - val_accuracy: 0.9835\n",
            "Epoch 440/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 6.3561e-05 - accuracy: 1.0000\n",
            "Epoch 440: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4.1234e-05 - accuracy: 1.0000 - val_loss: 0.6791 - val_accuracy: 0.9835\n",
            "Epoch 441/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 5.8146e-07 - accuracy: 1.0000\n",
            "Epoch 441: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.5612e-06 - accuracy: 1.0000 - val_loss: 0.6802 - val_accuracy: 0.9835\n",
            "Epoch 442/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 7.6713e-07 - accuracy: 1.0000\n",
            "Epoch 442: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0143 - accuracy: 0.9979 - val_loss: 0.6440 - val_accuracy: 0.9835\n",
            "Epoch 443/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 8.7340e-05 - accuracy: 1.0000\n",
            "Epoch 443: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.8130e-04 - accuracy: 1.0000 - val_loss: 0.6440 - val_accuracy: 0.9835\n",
            "Epoch 444/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0501 - accuracy: 0.9968    \n",
            "Epoch 444: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0325 - accuracy: 0.9979 - val_loss: 0.6424 - val_accuracy: 0.9835\n",
            "Epoch 445/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0036 - accuracy: 0.9968    \n",
            "Epoch 445: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 0.9979 - val_loss: 0.6687 - val_accuracy: 0.9835\n",
            "Epoch 446/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 5.4848e-04 - accuracy: 1.0000\n",
            "Epoch 446: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.8314e-04 - accuracy: 1.0000 - val_loss: 0.6786 - val_accuracy: 0.9835\n",
            "Epoch 447/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 2.4462e-07 - accuracy: 1.0000\n",
            "Epoch 447: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 5.0505e-07 - accuracy: 1.0000 - val_loss: 0.6808 - val_accuracy: 0.9835\n",
            "Epoch 448/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 2.1128e-07 - accuracy: 1.0000\n",
            "Epoch 448: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.2038e-05 - accuracy: 1.0000 - val_loss: 0.6840 - val_accuracy: 0.9835\n",
            "Epoch 449/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 7.0934e-06 - accuracy: 1.0000\n",
            "Epoch 449: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.7057 - val_accuracy: 0.9835\n",
            "Epoch 450/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 450: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7789 - val_accuracy: 0.9835\n",
            "Epoch 451/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 4.3134e-07 - accuracy: 1.0000\n",
            "Epoch 451: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.0185e-07 - accuracy: 1.0000 - val_loss: 0.7890 - val_accuracy: 0.9835\n",
            "Epoch 452/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 1.3168e-06 - accuracy: 1.0000\n",
            "Epoch 452: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.6312e-06 - accuracy: 1.0000 - val_loss: 0.7908 - val_accuracy: 0.9835\n",
            "Epoch 453/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 3.1061e-06 - accuracy: 1.0000\n",
            "Epoch 453: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.0770e-06 - accuracy: 1.0000 - val_loss: 0.7910 - val_accuracy: 0.9835\n",
            "Epoch 454/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 1.3760e-05 - accuracy: 1.0000\n",
            "Epoch 454: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 8.9317e-06 - accuracy: 1.0000 - val_loss: 0.7935 - val_accuracy: 0.9835\n",
            "Epoch 455/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 7.0958e-10 - accuracy: 1.0000\n",
            "Epoch 455: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4.9567e-10 - accuracy: 1.0000 - val_loss: 0.7939 - val_accuracy: 0.9835\n",
            "Epoch 456/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 0.0044 - accuracy: 0.9970    \n",
            "Epoch 456: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 0.9979 - val_loss: 1.0709 - val_accuracy: 0.9669\n",
            "Epoch 457/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 1.0040e-07 - accuracy: 1.0000\n",
            "Epoch 457: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 7.0137e-08 - accuracy: 1.0000 - val_loss: 1.1167 - val_accuracy: 0.9669\n",
            "Epoch 458/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 3.9886e-05 - accuracy: 1.0000\n",
            "Epoch 458: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.9917e-05 - accuracy: 1.0000 - val_loss: 1.1253 - val_accuracy: 0.9669\n",
            "Epoch 459/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 2.0933e-08 - accuracy: 1.0000\n",
            "Epoch 459: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.8055e-06 - accuracy: 1.0000 - val_loss: 1.1311 - val_accuracy: 0.9669\n",
            "Epoch 460/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 6.5842e-07 - accuracy: 1.0000\n",
            "Epoch 460: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4.6514e-07 - accuracy: 1.0000 - val_loss: 1.1326 - val_accuracy: 0.9669\n",
            "Epoch 461/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 1.3716e-07 - accuracy: 1.0000\n",
            "Epoch 461: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 8.9963e-08 - accuracy: 1.0000 - val_loss: 1.1328 - val_accuracy: 0.9669\n",
            "Epoch 462/500\n",
            "10/21 [=============>................] - ETA: 0s - loss: 2.2947e-07 - accuracy: 1.0000\n",
            "Epoch 462: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 7.1243e-05 - accuracy: 1.0000 - val_loss: 1.1357 - val_accuracy: 0.9669\n",
            "Epoch 463/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 1.0644e-09 - accuracy: 1.0000\n",
            "Epoch 463: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.0657e-08 - accuracy: 1.0000 - val_loss: 1.1377 - val_accuracy: 0.9669\n",
            "Epoch 464/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 7.3306e-04 - accuracy: 1.0000\n",
            "Epoch 464: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 5.1208e-04 - accuracy: 1.0000 - val_loss: 1.1664 - val_accuracy: 0.9669\n",
            "Epoch 465/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 1.4295e-05 - accuracy: 1.0000\n",
            "Epoch 465: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 9.2752e-06 - accuracy: 1.0000 - val_loss: 1.1773 - val_accuracy: 0.9669\n",
            "Epoch 466/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 6.6587e-07 - accuracy: 1.0000\n",
            "Epoch 466: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 6.0913e-07 - accuracy: 1.0000 - val_loss: 1.1803 - val_accuracy: 0.9669\n",
            "Epoch 467/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 9.5520e-09 - accuracy: 1.0000\n",
            "Epoch 467: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 6.1959e-09 - accuracy: 1.0000 - val_loss: 1.1806 - val_accuracy: 0.9669\n",
            "Epoch 468/500\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 6.7792e-06 - accuracy: 1.0000\n",
            "Epoch 468: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 6.9032e-06 - accuracy: 1.0000 - val_loss: 1.1821 - val_accuracy: 0.9669\n",
            "Epoch 469/500\n",
            "18/21 [========================>.....] - ETA: 0s - loss: 1.8698e-05 - accuracy: 1.0000\n",
            "Epoch 469: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 1.6794e-05 - accuracy: 1.0000 - val_loss: 1.1905 - val_accuracy: 0.9669\n",
            "Epoch 470/500\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.8884e-07 - accuracy: 1.0000\n",
            "Epoch 470: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 11ms/step - loss: 1.8884e-07 - accuracy: 1.0000 - val_loss: 1.1920 - val_accuracy: 0.9669\n",
            "Epoch 471/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 1.7739e-09 - accuracy: 1.0000\n",
            "Epoch 471: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 1.2392e-09 - accuracy: 1.0000 - val_loss: 1.1922 - val_accuracy: 0.9669\n",
            "Epoch 472/500\n",
            "18/21 [========================>.....] - ETA: 0s - loss: 4.4152e-09 - accuracy: 1.0000\n",
            "Epoch 472: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 3.9654e-09 - accuracy: 1.0000 - val_loss: 1.1922 - val_accuracy: 0.9669\n",
            "Epoch 473/500\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 7.4506e-10 - accuracy: 1.0000\n",
            "Epoch 473: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 11ms/step - loss: 7.4351e-10 - accuracy: 1.0000 - val_loss: 1.1922 - val_accuracy: 0.9669\n",
            "Epoch 474/500\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 474: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1922 - val_accuracy: 0.9669\n",
            "Epoch 475/500\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 475: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1922 - val_accuracy: 0.9669\n",
            "Epoch 476/500\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 3.7253e-09 - accuracy: 1.0000\n",
            "Epoch 476: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 3.7175e-09 - accuracy: 1.0000 - val_loss: 1.1922 - val_accuracy: 0.9669\n",
            "Epoch 477/500\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 1.8038e-08 - accuracy: 1.0000\n",
            "Epoch 477: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 1.7101e-08 - accuracy: 1.0000 - val_loss: 1.1923 - val_accuracy: 0.9669\n",
            "Epoch 478/500\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 3.4769e-09 - accuracy: 1.0000\n",
            "Epoch 478: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 11ms/step - loss: 3.4697e-09 - accuracy: 1.0000 - val_loss: 1.1924 - val_accuracy: 0.9669\n",
            "Epoch 479/500\n",
            "18/21 [========================>.....] - ETA: 0s - loss: 5.5189e-10 - accuracy: 1.0000\n",
            "Epoch 479: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 4.9567e-10 - accuracy: 1.0000 - val_loss: 1.1924 - val_accuracy: 0.9669\n",
            "Epoch 480/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 1.7531e-09 - accuracy: 1.0000\n",
            "Epoch 480: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 1.4870e-09 - accuracy: 1.0000 - val_loss: 1.1924 - val_accuracy: 0.9669\n",
            "Epoch 481/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 5.8371e-05 - accuracy: 1.0000\n",
            "Epoch 481: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 3.4950e-05 - accuracy: 1.0000 - val_loss: 1.1910 - val_accuracy: 0.9669\n",
            "Epoch 482/500\n",
            "21/21 [==============================] - ETA: 0s - loss: 3.5339e-07 - accuracy: 1.0000\n",
            "Epoch 482: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 3.5339e-07 - accuracy: 1.0000 - val_loss: 1.1908 - val_accuracy: 0.9669\n",
            "Epoch 483/500\n",
            "21/21 [==============================] - ETA: 0s - loss: 2.5005e-07 - accuracy: 1.0000\n",
            "Epoch 483: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 2.5005e-07 - accuracy: 1.0000 - val_loss: 1.1909 - val_accuracy: 0.9669\n",
            "Epoch 484/500\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 1.1136e-07 - accuracy: 1.0000\n",
            "Epoch 484: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 1.0558e-07 - accuracy: 1.0000 - val_loss: 1.1910 - val_accuracy: 0.9669\n",
            "Epoch 485/500\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 485: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1910 - val_accuracy: 0.9669\n",
            "Epoch 486/500\n",
            "21/21 [==============================] - ETA: 0s - loss: 6.4002e-05 - accuracy: 1.0000\n",
            "Epoch 486: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 6.4002e-05 - accuracy: 1.0000 - val_loss: 1.2421 - val_accuracy: 0.9669\n",
            "Epoch 487/500\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 487: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 11ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2287 - val_accuracy: 0.9669\n",
            "Epoch 488/500\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 488: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2232 - val_accuracy: 0.9669\n",
            "Epoch 489/500\n",
            "19/21 [==========================>...] - ETA: 0s - loss: 2.6142e-10 - accuracy: 1.0000\n",
            "Epoch 489: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 2.4784e-10 - accuracy: 1.0000 - val_loss: 1.2227 - val_accuracy: 0.9669\n",
            "Epoch 490/500\n",
            "20/21 [===========================>..] - ETA: 0s - loss: 3.0242e-06 - accuracy: 1.0000\n",
            "Epoch 490: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 9ms/step - loss: 3.0179e-06 - accuracy: 1.0000 - val_loss: 1.2260 - val_accuracy: 0.9669\n",
            "Epoch 491/500\n",
            "17/21 [=======================>......] - ETA: 0s - loss: 1.5288e-06 - accuracy: 1.0000\n",
            "Epoch 491: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 12ms/step - loss: 1.2968e-06 - accuracy: 1.0000 - val_loss: 1.2279 - val_accuracy: 0.9669\n",
            "Epoch 492/500\n",
            "18/21 [========================>.....] - ETA: 0s - loss: 8.9682e-08 - accuracy: 1.0000\n",
            "Epoch 492: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 8.0546e-08 - accuracy: 1.0000 - val_loss: 1.2283 - val_accuracy: 0.9669\n",
            "Epoch 493/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 493: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4.3824e-06 - accuracy: 1.0000 - val_loss: 1.2285 - val_accuracy: 0.9669\n",
            "Epoch 494/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 1.8583e-06 - accuracy: 1.0000\n",
            "Epoch 494: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 1.2103e-06 - accuracy: 1.0000 - val_loss: 1.2283 - val_accuracy: 0.9669\n",
            "Epoch 495/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 1.1708e-08 - accuracy: 1.0000\n",
            "Epoch 495: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.0570e-08 - accuracy: 1.0000 - val_loss: 1.2282 - val_accuracy: 0.9669\n",
            "Epoch 496/500\n",
            "14/21 [===================>..........] - ETA: 0s - loss: 3.5479e-10 - accuracy: 1.0000\n",
            "Epoch 496: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 2.1895e-06 - accuracy: 1.0000 - val_loss: 1.2290 - val_accuracy: 0.9669\n",
            "Epoch 497/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 7.1360e-05 - accuracy: 1.0000\n",
            "Epoch 497: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4.7371e-05 - accuracy: 1.0000 - val_loss: 1.2572 - val_accuracy: 0.9669\n",
            "Epoch 498/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 1.5283e-09 - accuracy: 1.0000\n",
            "Epoch 498: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 1.9827e-09 - accuracy: 1.0000 - val_loss: 1.2609 - val_accuracy: 0.9669\n",
            "Epoch 499/500\n",
            "12/21 [================>.............] - ETA: 0s - loss: 8.6923e-09 - accuracy: 1.0000\n",
            "Epoch 499: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 4.7530e-07 - accuracy: 1.0000 - val_loss: 1.2614 - val_accuracy: 0.9669\n",
            "Epoch 500/500\n",
            "13/21 [=================>............] - ETA: 0s - loss: 4.1647e-08 - accuracy: 1.0000\n",
            "Epoch 500: val_loss did not improve from 0.20339\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 3.1971e-08 - accuracy: 1.0000 - val_loss: 1.2617 - val_accuracy: 0.9669\n",
            "Training completed in time:  0:01:22.862927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
        "print(test_accuracy[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGBGVowXUOEs",
        "outputId": "f37e04eb-abc1-4283-9956-be91a7937523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9834710955619812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=train.history\n",
        "# loss_values=history_dict['loss']\n",
        "# acc_values=history_dict['accuracy']\n",
        "# val_loss_values = history_dict['val_loss']\n",
        "# val_acc_values=history_dict['val_accuracy']\n",
        "# epochs=range(1,501)\n",
        "# fig,(ax1,ax2)=plt.subplots(1,2,figsize=(15,5))\n",
        "# ax1.plot(epochs,loss_values,'bo',label='Training Loss')\n",
        "# ax1.plot(epochs,val_loss_values,'orange', label='Validation Loss')\n",
        "# ax1.set_title('Training and validation loss')\n",
        "# ax1.set_xlabel('Epochs')\n",
        "# ax1.set_ylabel('Loss')\n",
        "# ax1.legend()\n",
        "# ax2.plot(epochs,acc_values,'bo', label='Training accuracy')\n",
        "# ax2.plot(epochs,val_acc_values,'orange',label='Validation accuracy')\n",
        "# ax2.set_title('Training and validation accuracy')\n",
        "# ax2.set_xlabel('Epochs')\n",
        "# ax2.set_ylabel('Accuracy')\n",
        "# ax2.legend()\n",
        "# plt.show()\n",
        "plt.plot(history['accuracy'])\n",
        "plt.plot(history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "40cVEXPRUzKy",
        "outputId": "d1422907-0d5c-43fb-e6e7-ff7740337622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(history_dict[\"val_loss\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_VWlgFCV8yV",
        "outputId": "de98dc4a-02dd-4657-9d47-69c564ef2eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5339659452438354, 0.528266191482544, 0.518191397190094, 0.5092535614967346, 0.5033121109008789, 0.42734023928642273, 0.40835461020469666, 0.37165963649749756, 0.46206334233283997, 0.457847535610199, 0.44975608587265015, 0.42010924220085144, 0.44055142998695374, 0.4810270369052887, 0.4729229211807251, 0.4729752838611603, 0.47522997856140137, 0.47546055912971497, 0.44015756249427795, 0.517182469367981, 0.6065447926521301, 0.6432499885559082, 0.6173093914985657, 0.6155855059623718, 0.7394790649414062, 0.7794801592826843, 0.7499663233757019, 0.734672486782074, 0.710176408290863, 0.6909340023994446, 0.661294162273407, 0.6216256618499756, 0.6253390908241272, 0.661332368850708, 0.7089481949806213, 0.7378442883491516, 0.7415471076965332, 0.705409049987793, 0.7002049684524536, 0.6994560956954956, 0.7923867106437683, 1.0848506689071655, 1.1148239374160767, 0.9751065373420715, 0.9055463075637817, 0.8326457738876343, 0.7692489624023438, 0.6455152630805969, 0.7714452147483826, 0.8538333773612976, 0.8565043807029724, 0.8483113050460815, 0.836646318435669, 0.829696536064148, 0.8288047909736633, 0.828680694103241, 0.725953221321106, 0.5884536504745483, 0.5890629291534424, 0.5889684557914734, 0.5891036987304688, 0.6131448745727539, 0.6276301145553589, 0.5714983344078064, 0.5587509870529175, 0.5657837986946106, 0.56780606508255, 0.5681663155555725, 0.5682107210159302, 0.5681300163269043, 0.568081796169281, 0.5690324902534485, 0.5815941691398621, 0.5862717032432556, 0.6659411787986755, 0.7497628927230835, 0.714360773563385, 0.7147118449211121, 0.7147527933120728, 0.7142229080200195, 0.7141640186309814, 0.7155747413635254, 0.7167450189590454, 0.7144968509674072, 0.7057312726974487, 0.7046899795532227, 0.7045676112174988, 0.7046757340431213, 0.6887109279632568, 0.680202841758728, 0.6792850494384766, 0.6811763644218445, 0.6816270351409912, 0.6276822686195374, 0.6460531949996948, 0.6539859771728516, 0.6548935174942017, 0.6552309989929199, 0.6558303236961365, 0.6561309099197388, 0.6561752557754517, 0.656180739402771, 0.6538099050521851, 0.648321270942688, 0.647676408290863, 0.6475934386253357, 0.647596001625061, 0.6475979685783386, 0.7248349189758301, 0.7592419981956482, 0.7977529764175415, 0.8035538792610168, 0.8052229881286621, 0.8056535720825195, 0.7996450662612915, 0.801278829574585, 0.802854061126709, 0.7998178005218506, 0.7912410497665405, 0.7902926802635193, 0.9465953707695007, 0.982499361038208, 0.9870244264602661, 0.9879427552223206, 0.9880484342575073, 0.9880642890930176, 0.9880688190460205, 0.9913699626922607, 0.9777764081954956, 0.976271390914917, 0.9761072993278503, 0.9753670692443848, 0.975197970867157, 0.9752640128135681, 0.975360095500946, 0.9755522608757019, 0.9755828976631165, 0.9755857586860657, 0.975934624671936, 0.9814770221710205, 0.9863675832748413, 1.0024791955947876, 1.0049647092819214, 0.8673233985900879, 0.2033884972333908, 0.5096809267997742, 0.6106454730033875, 0.7041512727737427, 0.21520239114761353, 0.7579188942909241, 1.1013860702514648, 1.1694241762161255, 1.1918116807937622, 1.2034038305282593, 1.039610505104065, 0.6237442493438721, 0.3190814256668091, 0.7277370691299438, 0.8357077240943909, 0.8180944323539734, 0.2682044506072998, 0.4577217102050781, 0.4673062562942505, 0.47265371680259705, 0.5611292123794556, 0.7338308095932007, 0.8048508167266846, 0.8443053960800171, 0.8602166771888733, 0.8745962381362915, 0.8847484588623047, 0.9653113484382629, 0.9763880968093872, 0.9999902248382568, 1.0031332969665527, 1.01068913936615, 1.0140835046768188, 0.977688193321228, 0.9934954643249512, 1.2155359983444214, 1.2371965646743774, 1.2409530878067017, 0.6145760416984558, 0.7495568990707397, 0.7816735506057739, 0.933609664440155, 1.0330140590667725, 1.0474340915679932, 0.9261422157287598, 1.474600076675415, 1.7072423696517944, 1.5376793146133423, 1.4992741346359253, 1.2281157970428467, 0.9833223223686218, 1.2918593883514404, 1.133540391921997, 0.8364824056625366, 1.488483190536499, 1.5857661962509155, 1.6007030010223389, 1.1104835271835327, 1.640489935874939, 2.011611223220825, 1.6739459037780762, 1.8540599346160889, 1.8842378854751587, 1.2504905462265015, 1.2015451192855835, 1.2441562414169312, 1.2751494646072388, 1.2788147926330566, 1.2792645692825317, 1.2793254852294922, 1.2793346643447876, 1.2793362140655518, 1.2876014709472656, 1.2854607105255127, 1.2870738506317139, 1.2918964624404907, 1.318601369857788, 2.0773444175720215, 2.3761777877807617, 2.406304359436035, 2.4095051288604736, 2.2960243225097656, 2.287853479385376, 2.2575597763061523, 2.251565456390381, 2.250917434692383, 2.250852584838867, 2.2508456707000732, 2.2511777877807617, 2.251450777053833, 2.251946449279785, 2.2853994369506836, 2.4794678688049316, 2.5341691970825195, 2.5405657291412354, 2.541295051574707, 2.5285634994506836, 2.526508331298828, 2.5277512073516846, 2.527780532836914, 2.527757167816162, 2.5902836322784424, 2.6048808097839355, 2.619993209838867, 2.622185707092285, 2.627535820007324, 2.633662700653076, 2.6326212882995605, 2.632516622543335, 1.5294469594955444, 2.458247661590576, 3.752823829650879, 2.3433613777160645, 2.1764633655548096, 1.6523860692977905, 1.5790929794311523, 1.7090842723846436, 1.724726915359497, 1.7331020832061768, 1.7364699840545654, 1.5650254487991333, 1.463496446609497, 1.6598447561264038, 1.716341495513916, 1.7084956169128418, 1.7095540761947632, 1.7188100814819336, 1.72603178024292, 1.7317969799041748, 1.7347376346588135, 1.735183835029602, 1.7340834140777588, 1.7344499826431274, 1.7345008850097656, 1.745737910270691, 1.749975323677063, 1.7472586631774902, 1.7475005388259888, 1.748489260673523, 1.7521543502807617, 1.84027099609375, 1.9369165897369385, 1.966134786605835, 1.9902608394622803, 2.0067734718322754, 2.008646011352539, 2.0072128772735596, 2.0243096351623535, 2.029749631881714, 2.1713013648986816, 1.8689310550689697, 1.780545711517334, 1.7701517343521118, 1.786439299583435, 1.7999331951141357, 1.8168232440948486, 1.8070387840270996, 1.7891925573349, 1.7837928533554077, 1.7832001447677612, 1.788946270942688, 1.7895838022232056, 1.7938176393508911, 1.812330722808838, 1.8174448013305664, 1.8194745779037476, 1.8300725221633911, 1.8688527345657349, 1.8775625228881836, 1.8161112070083618, 1.7891710996627808, 1.7909188270568848, 1.7859859466552734, 1.7786853313446045, 1.7789634466171265, 1.7790172100067139, 1.7790228128433228, 1.7656078338623047, 1.7212283611297607, 1.7165204286575317, 1.7192522287368774, 1.73521888256073, 1.742451786994934, 1.746561884880066, 1.7478067874908447, 1.750014066696167, 1.750777244567871, 1.7508913278579712, 1.7509346008300781, 1.7509772777557373, 1.758413314819336, 1.8390331268310547, 1.9230964183807373, 1.966638445854187, 1.9897829294204712, 1.9945240020751953, 1.9953722953796387, 1.9959120750427246, 1.999495029449463, 2.0030086040496826, 2.003396987915039, 2.0034401416778564, 2.0034754276275635, 2.0212202072143555, 2.0911598205566406, 2.0996227264404297, 2.100555181503296, 2.1006581783294678, 2.127591609954834, 1.555745244026184, 1.4863306283950806, 2.595261335372925, 3.0113906860351562, 2.783633232116699, 1.177856206893921, 1.3926730155944824, 2.8347067832946777, 3.0698983669281006, 3.106184244155884, 3.110276937484741, 3.1107304096221924, 1.1739526987075806, 1.1235629320144653, 0.8540128469467163, 1.3710947036743164, 1.103642225265503, 0.8303004503250122, 0.7801250219345093, 2.061047077178955, 1.9312655925750732, 1.9073761701583862, 1.7888199090957642, 1.5864768028259277, 1.6031765937805176, 1.5421298742294312, 1.5270447731018066, 1.5239111185073853, 1.5287928581237793, 1.5254395008087158, 1.5226082801818848, 0.7353454828262329, 0.7276248335838318, 0.7267796397209167, 0.7266860604286194, 0.7266757488250732, 1.066914439201355, 1.457305908203125, 1.5019965171813965, 1.5068374872207642, 1.499764084815979, 1.5327101945877075, 1.4977290630340576, 1.2177538871765137, 1.185078740119934, 0.9744044542312622, 0.9153148531913757, 0.9112624526023865, 0.9447381496429443, 0.9704242944717407, 1.0159631967544556, 1.0180796384811401, 1.0183191299438477, 1.01835036277771, 1.0183583498001099, 1.0575252771377563, 1.0642176866531372, 1.064963698387146, 1.0770152807235718, 1.0790201425552368, 0.9141417741775513, 0.8476261496543884, 0.8406121134757996, 0.8446498513221741, 0.8456804156303406, 0.8546380996704102, 0.8571207523345947, 0.8578879833221436, 0.8590970635414124, 0.8592407703399658, 0.8592734932899475, 0.8593031167984009, 0.8646915555000305, 1.0226308107376099, 1.122616171836853, 1.1307162046432495, 1.1316136121749878, 1.1356788873672485, 1.1418536901474, 1.1492575407028198, 1.1520556211471558, 1.1543865203857422, 1.1546440124511719, 0.8734418749809265, 0.689723789691925, 0.6725170016288757, 0.6790755987167358, 0.680244505405426, 0.6440374255180359, 0.643988847732544, 0.6424061059951782, 0.668717622756958, 0.678581953048706, 0.680826723575592, 0.6840305328369141, 0.7056750655174255, 0.7789015769958496, 0.7889795303344727, 0.7908487915992737, 0.7909784317016602, 0.7934830188751221, 0.7938910722732544, 1.0709044933319092, 1.116727590560913, 1.125329852104187, 1.1310832500457764, 1.1326313018798828, 1.1328232288360596, 1.1357314586639404, 1.1376873254776, 1.1664485931396484, 1.1773436069488525, 1.1803449392318726, 1.1805683374404907, 1.1820933818817139, 1.1904821395874023, 1.1919947862625122, 1.1921640634536743, 1.1921857595443726, 1.1921907663345337, 1.1921913623809814, 1.1921913623809814, 1.1921930313110352, 1.1923314332962036, 1.1923766136169434, 1.1923909187316895, 1.1923938989639282, 1.191034197807312, 1.1907557249069214, 1.190866470336914, 1.1909581422805786, 1.1909708976745605, 1.2421185970306396, 1.2287182807922363, 1.2232365608215332, 1.2226781845092773, 1.22601318359375, 1.2279361486434937, 1.2283046245574951, 1.2285295724868774, 1.2282658815383911, 1.2281904220581055, 1.2290146350860596, 1.2571687698364258, 1.260876178741455, 1.2614492177963257, 1.2616829872131348]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "8-MCx-SoYgJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename=\"/content/test_file.wav\"\n",
        "#preprocess the audio file\n",
        "audio, sample_rate = librosa.load(filename)\n",
        "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "#Reshape MFCC feature to 2-D array\n",
        "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
        "#predicted_label=model.predict_classes(mfccs_scaled_features)\n",
        "x_predict=model.predict(mfccs_scaled_features)\n",
        "predicted_label=np.argmax(x_predict,axis=1)\n",
        "print(predicted_label)\n",
        "prediction_class = labelencoder.inverse_transform(predicted_label)\n",
        "print(prediction_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpIZ4eP7X7dF",
        "outputId": "834a54c6-4f7a-4fc4-b33f-ae9ee5d22262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 107ms/step\n",
            "[0]\n",
            "['ambulance']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename=\"/content/drive/MyDrive/SATS/Dataset/Audio_Dataset/sound_469.wav\"\n",
        "#preprocess the audio file\n",
        "audio, sample_rate = librosa.load(filename)\n",
        "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "#Reshape MFCC feature to 2-D array\n",
        "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
        "#predicted_label=model.predict_classes(mfccs_scaled_features)\n",
        "x_predict=model.predict(mfccs_scaled_features)\n",
        "predicted_label=np.argmax(x_predict,axis=1)\n",
        "print(predicted_label)\n",
        "prediction_class = labelencoder.inverse_transform(predicted_label)\n",
        "print(prediction_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEcyi2WvZk88",
        "outputId": "89bade3c-ae95-497e-8ef8-261c20ed1e5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "[2]\n",
            "['traffic']\n"
          ]
        }
      ]
    }
  ]
}